{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/img/icon_wechat.png","path":"img/icon_wechat.png","modified":0,"renderable":0},{"_id":"source/pdfs/jensen_inequality.pdf","path":"pdfs/jensen_inequality.pdf","modified":0,"renderable":0},{"_id":"source/img/404-bg.jpg","path":"img/404-bg.jpg","modified":0,"renderable":0},{"_id":"source/img/article/tag.png","path":"img/article/tag.png","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/css/archive.styl","path":"css/archive.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/beantech.css","path":"css/beantech.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/beantech.min.css","path":"css/beantech.min.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/donate.css","path":"css/donate.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/rocket.styl","path":"css/rocket.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/signature.styl","path":"css/signature.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/toc.styl","path":"css/toc.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/widget.styl","path":"css/widget.styl","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/click_show_text.js","path":"js/click_show_text.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/hux-blog.js","path":"js/hux-blog.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/smoothscroll.js","path":"js/smoothscroll.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/toc.js","path":"js/toc.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/tagsCloud.js","path":"js/tagsCloud.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"source/img/header_img/Iron-Man-3.jpg","path":"img/header_img/Iron-Man-3.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/about.jpg","path":"img/header_img/about.jpg","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/archive.jpg","path":"img/header_img/archive.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/archives-widget.jpg","path":"img/header_img/archives-widget.jpg","modified":0,"renderable":0},{"_id":"source/img/ironman-draw.png","path":"img/ironman-draw.png","modified":0,"renderable":0},{"_id":"source/img/signature/BeanTechSign-white.png","path":"img/signature/BeanTechSign-white.png","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/css/bootstrap.css","path":"css/bootstrap.css","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/images/ironman.png","path":"css/images/ironman.png","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/images/rocket.png","path":"css/images/rocket.png","modified":0,"renderable":1},{"_id":"themes/huweihuang/source/css/images/up-arrow.png","path":"css/images/up-arrow.png","modified":0,"renderable":1},{"_id":"source/img/header_img/tf-logo-dark.png","path":"img/header_img/tf-logo-dark.png","modified":0,"renderable":0},{"_id":"themes/huweihuang/source/js/jquery.js","path":"js/jquery.js","modified":0,"renderable":1},{"_id":"source/img/article_header/article_bg.jpg","path":"img/article_header/article_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/avatar/ironman.png","path":"img/avatar/ironman.png","modified":0,"renderable":0},{"_id":"source/img/signature/BeanTechSign-black.png","path":"img/signature/BeanTechSign-black.png","modified":0,"renderable":0},{"_id":"source/img/article/huweihuang_blog.png","path":"img/article/huweihuang_blog.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home.jpg","path":"img/header_img/home.jpg","modified":0,"renderable":0},{"_id":"source/img/beantech-desktop.png","path":"img/beantech-desktop.png","modified":0,"renderable":0},{"_id":"source/img/header_img/tag-bg.png","path":"img/header_img/tag-bg.png","modified":0,"renderable":0},{"_id":"source/img/header_img/tag.png","path":"img/header_img/tag.png","modified":0,"renderable":0},{"_id":"source/img/article_header/article_header.png","path":"img/article_header/article_header.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home2.png","path":"img/header_img/home2.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-o.png","path":"img/header_img/home-bg-o.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-2-dark.png","path":"img/header_img/home-bg-2-dark.png","modified":0,"renderable":0},{"_id":"source/img/header_img/archive-bg.png","path":"img/header_img/archive-bg.png","modified":0,"renderable":0},{"_id":"source/img/header_img/404.png","path":"img/header_img/404.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/404.md","hash":"83c2c6d587beaa967a976e5969d60fa97fcdbe55","modified":1563017124390},{"_id":"source/CNAME","hash":"947ea2d717f53e46b49eb7f5fcef6d16b58bd86e","modified":1563757827086},{"_id":"themes/huweihuang/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1556349407000},{"_id":"themes/huweihuang/_config.yml","hash":"8df3cd71fc4ff71d5eda6e35a1bd122a5baf313d","modified":1563252514708},{"_id":"source/_posts/.HMM.md.swp","hash":"32f7c66d3ce2055cd793fb578fcdf2c8cf78bd6f","modified":1564049453849},{"_id":"source/_posts/;","hash":"ab0b76591bec83537add4c6ea19b6118b3c1f284","modified":1563522048087},{"_id":"source/_posts/EM.md","hash":"2399f0b7bcf31c78604cfdd4fb44d6168e5e6d3d","modified":1563861657751},{"_id":"source/_posts/GMM.md","hash":"17e32348a804b9a7f9989879d7793fc25b89da25","modified":1563799714827},{"_id":"source/_posts/HMM.md","hash":"7ef54a2cb44d83f5d5f4e24007e40347774f25a2","modified":1564145522997},{"_id":"source/_posts/debug.log","hash":"35ffb47bcd655dc336ab7bae32a342a4376576d9","modified":1563249157203},{"_id":"source/_posts/hexo-theme-huweihuang.md","hash":"b3202dc2aa26bdc6597e1d79721cd42ef292bad3","modified":1563778428599},{"_id":"source/_posts/hexobug.md","hash":"0b1b499a76d8431bb62db9ef9ee4257828e7c3ea","modified":1563254673073},{"_id":"source/_posts/scripts.md","hash":"3d6b8eef67cc12d513bdc7600f61dc31dfbcbc7d","modified":1563758392000},{"_id":"source/about/index.md","hash":"ebca34cfe8d13ec641d17fcfec0127a966338f8e","modified":1563017124422},{"_id":"source/archive/index.md","hash":"279ff19668395f5c6b26417da99d2c1f3ecd5886","modified":1563017124422},{"_id":"source/img/icon_wechat.png","hash":"4188058026609de06c6cac88b349a2da831a1783","modified":1556349407000},{"_id":"source/tags/index.md","hash":"9d558ce28d0d44c3463517088689bbca44bbb364","modified":1563017124690},{"_id":"themes/huweihuang/languages_to_be_added/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1556349407000},{"_id":"themes/huweihuang/languages_to_be_added/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1556349407000},{"_id":"themes/huweihuang/layout/.index.ejs.swp","hash":"f51314cf33b28ac418e27745f216ddbae55b4998","modified":1563242040274},{"_id":"themes/huweihuang/layout/404.ejs","hash":"40de38bd399f6f4aef0d6c63c7b13b02d74f1c56","modified":1556349407000},{"_id":"themes/huweihuang/layout/about.ejs","hash":"edcf8fa3bf7093c974d418ffef42ac89c19af128","modified":1556349407000},{"_id":"themes/huweihuang/layout/archive.ejs","hash":"b25c71964b3d2db93215df6b411f89bb948c5114","modified":1556349407000},{"_id":"themes/huweihuang/layout/index.ejs","hash":"6f558ff92f53bf47bc39cef6959d302b6bb9207b","modified":1563242032237},{"_id":"themes/huweihuang/layout/keynote.ejs","hash":"f5689862281e34dbe8402b0e72f632902e53e88b","modified":1556349407000},{"_id":"themes/huweihuang/layout/layout.ejs","hash":"c0248f230d3d9526b3c2de87712fce13c5c693e9","modified":1556349407000},{"_id":"themes/huweihuang/layout/page.ejs","hash":"8a6f5c6193eec16ffab5f24dda3dc1bc4c0cff9a","modified":1556349407000},{"_id":"themes/huweihuang/layout/post.ejs","hash":"90718a835168c824c9cbeb0353bfd60c6b1e493c","modified":1556349407000},{"_id":"themes/huweihuang/layout/tags.ejs","hash":"2c72eb2e89130658aa068d80d27b561b509c5dcd","modified":1556349407000},{"_id":"source/pdfs/jensen_inequality.pdf","hash":"7aee3e40611d8e31808a44b555199bc0fe0c09e8","modified":1563785682265},{"_id":"source/img/404-bg.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1563017124422},{"_id":"source/img/article/tag.png","hash":"c8632d64d9471009098b84f70273e63037a4e7b8","modified":1556349407000},{"_id":"themes/huweihuang/layout/_partial/footer.ejs","hash":"4c1a136fb69496207b4aa43d5dbde4bc1a03c4d1","modified":1563247885565},{"_id":"themes/huweihuang/layout/_partial/head.ejs","hash":"b004bea62cdc46fb05f4c2851f5f968d73f3dd66","modified":1556349407000},{"_id":"themes/huweihuang/layout/_partial/header.ejs","hash":"04fa99d2b7465ce6a5ed456927081a6e993b9c88","modified":1556349407000},{"_id":"themes/huweihuang/layout/_partial/nav.ejs","hash":"f6f1ac0fbcb362546e37a35d6cb362f69fc5f0af","modified":1556349407000},{"_id":"themes/huweihuang/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1556349407000},{"_id":"themes/huweihuang/layout/_partial/sidebar.ejs","hash":"2e4e528a555917b2a267da4db2440bcc4a7a65ab","modified":1556349407000},{"_id":"themes/huweihuang/layout/_partial/toc.ejs","hash":"40e11b303df113c64a5ca35b79dd53c824010c09","modified":1556349407000},{"_id":"themes/huweihuang/layout/_widget/archive.ejs","hash":"7594929d472806ca4c64d9906d9903a96de111a0","modified":1556349407000},{"_id":"themes/huweihuang/layout/_widget/category.ejs","hash":"1cf485def07dc06e870dc9613767c6c614bcf428","modified":1556349407000},{"_id":"themes/huweihuang/layout/_widget/featured-tags.ejs","hash":"93e21c2014929ba5366cb73d4db0382a55aa487c","modified":1556349407000},{"_id":"themes/huweihuang/layout/_widget/friends-blog.ejs","hash":"734d3775017aedac185028924baf890a71a74548","modified":1556349407000},{"_id":"themes/huweihuang/layout/_widget/recent-posts.ejs","hash":"e08ab8ba60e31638006acf27f066b989a0a3c433","modified":1556349407000},{"_id":"themes/huweihuang/layout/_widget/short-about.ejs","hash":"315de02246f07c747c32495e107ad7b19cb3ff54","modified":1556349407000},{"_id":"themes/huweihuang/source/css/archive.styl","hash":"715bcbd085eb95ec26c9805c11c374919cde971c","modified":1556349407000},{"_id":"themes/huweihuang/source/css/beantech.css","hash":"4c361354fd8e9851923fb21a620bc079380ebcd8","modified":1556349407000},{"_id":"themes/huweihuang/source/css/beantech.min.css","hash":"05a06230b1a9eca0b30cece54a397008cb77dc50","modified":1556349407000},{"_id":"themes/huweihuang/source/css/donate.css","hash":"f65ac8363d8d215adb896158e7b45165db259a47","modified":1556349407000},{"_id":"themes/huweihuang/source/css/highlight.styl","hash":"e842080e6d580f0f70a7df71fbde3c4e49463c19","modified":1556349407000},{"_id":"themes/huweihuang/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1556349407000},{"_id":"themes/huweihuang/source/css/rocket.styl","hash":"191135ed8c4d93b5b1b0bbe0e0c77d2e679c026b","modified":1563504208698},{"_id":"themes/huweihuang/source/css/signature.styl","hash":"88159b31c59d59c01a0b534af57242662a2a3969","modified":1556349407000},{"_id":"themes/huweihuang/source/css/toc.styl","hash":"631e97f634d30f53314e2fec8bdde267c1c49f4c","modified":1556349407000},{"_id":"themes/huweihuang/source/css/widget.styl","hash":"7a9f735f5ef323dc2950fbd9d76daa16c9a0f1a9","modified":1556349407000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1556349407000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1556349407000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1556349407000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1556349407000},{"_id":"themes/huweihuang/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1556349407000},{"_id":"themes/huweihuang/source/js/click_show_text.js","hash":"1d4da8ff7daf10a99a197292c3948731c8362eca","modified":1563247726041},{"_id":"themes/huweihuang/source/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1556349407000},{"_id":"themes/huweihuang/source/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1556349407000},{"_id":"themes/huweihuang/source/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1556349407000},{"_id":"themes/huweihuang/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1556349407000},{"_id":"themes/huweihuang/source/js/smoothscroll.js","hash":"134a1ad40b68efec27575a2cdd48eccf8a63bf71","modified":1556349407000},{"_id":"themes/huweihuang/source/js/toc.js","hash":"41e52551731854224c249d53010c1bae5aa92ffa","modified":1556349407000},{"_id":"themes/huweihuang/source/js/tagsCloud.js","hash":"453b31fd6d6bb3e5b405b5729ec328ab760c2bef","modified":1556349407000},{"_id":"themes/huweihuang/source/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1556349407000},{"_id":"source/img/header_img/Iron-Man-3.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1563017124430},{"_id":"source/img/header_img/about.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1556349407000},{"_id":"themes/huweihuang/source/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1556349407000},{"_id":"themes/huweihuang/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1556349407000},{"_id":"themes/huweihuang/source/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1556349407000},{"_id":"themes/huweihuang/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1556349407000},{"_id":"source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1563017124430},{"_id":"source/img/header_img/archive.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1556349407000},{"_id":"source/img/header_img/archives-widget.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1556349407000},{"_id":"source/img/ironman-draw.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1563017124574},{"_id":"source/img/signature/BeanTechSign-white.png","hash":"34289ed41cf9ddac2d56be46fbb1515b7d5913cd","modified":1556349407000},{"_id":"themes/huweihuang/source/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1556349407000},{"_id":"themes/huweihuang/source/css/images/ironman.png","hash":"2f0db0ab15d466c4065d9f6102fdf829726d9e3f","modified":1556349407000},{"_id":"themes/huweihuang/source/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1556349407000},{"_id":"themes/huweihuang/source/css/images/up-arrow.png","hash":"34559d16cb6160e87ff319fe7576a0d16c4e11ff","modified":1563503223498},{"_id":"source/img/header_img/tf-logo-dark.png","hash":"5c7bf8ade9de134f8c77a3c59e575abe9fc6cdd4","modified":1563017124486},{"_id":"themes/huweihuang/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1556349407000},{"_id":"source/img/article_header/article_bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1556349407000},{"_id":"source/img/avatar/ironman.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1556349407000},{"_id":"source/img/signature/BeanTechSign-black.png","hash":"94b7102e819fd6ee082d3fb0166f4de7458c22ff","modified":1556349407000},{"_id":"source/img/article/huweihuang_blog.png","hash":"392cf8b33be6c752dd908e027fa3346a6ecd58ab","modified":1556349407000},{"_id":"source/img/header_img/home.jpg","hash":"8f1c440427a4aa86b623503a926c027e2e10cd66","modified":1556349407000},{"_id":"source/img/beantech-desktop.png","hash":"4a8f8b209c9db8fd5209f15b8e4590525e258b0f","modified":1563017124430},{"_id":"source/img/header_img/tag-bg.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1563017124486},{"_id":"source/img/header_img/tag.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1556349407000},{"_id":"source/_posts/HMM/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1563786590910},{"_id":"source/_posts/hexo-theme-huweihuang/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1556349407000},{"_id":"source/_posts/scripts/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1563237469102},{"_id":"source/img/article_header/article_header.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1556349407000},{"_id":"source/_posts/GMM/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1563786515677},{"_id":"source/_posts/EM/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1563247762347},{"_id":"source/img/header_img/home2.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1556349407000},{"_id":"source/img/header_img/home-bg-o.png","hash":"134ece4cb4c49c7ca1403a5afe7f46d0e2f9ecbb","modified":1556349407000},{"_id":"source/img/header_img/home-bg-2-dark.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1563017124438},{"_id":"source/img/header_img/archive-bg.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1563017124434},{"_id":"source/img/header_img/404.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1556349407000},{"_id":"public/404.html","hash":"c4a7b3ef8e38d2926c4fa8fc9c6ae5003f290565","modified":1564145943181},{"_id":"public/tags/index.html","hash":"ef4ba4ef2364524444de95ac2f15adc6aed2e7e5","modified":1564145943181},{"_id":"public/article/HMM/index.html","hash":"c34055e4719f35985f4e8009fe646eac08090636","modified":1564145943181},{"_id":"public/article/GMM/index.html","hash":"37bf588e91951555c2666e4939fa04456508222d","modified":1564145943181},{"_id":"public/article/hexobug/index.html","hash":"cd78c0a5871f6c299874c40a0e260cfcfe569212","modified":1564145943181},{"_id":"public/article/EM/index.html","hash":"143097c045fe036d6b3638040b44b39f9c93940b","modified":1564145943182},{"_id":"public/article/scripts/index.html","hash":"20207d0947889c9163d59d7364cd753b31781deb","modified":1564145943182},{"_id":"public/article/hexo-theme-huweihuang/index.html","hash":"49c0a732516f01033491df9468df9e2b105ca1cd","modified":1564145943182},{"_id":"public/about/index.html","hash":"4b6a2e3028bf81bb6469bcc7178d29b81c7cd60c","modified":1564145943182},{"_id":"public/archive/index.html","hash":"e3981c96e7ba5879034f8c8d2574a2c667a7aa40","modified":1564145943182},{"_id":"public/archives/index.html","hash":"52541f3be7432ca447a42a84f3facefe5182c3f0","modified":1564145943182},{"_id":"public/archives/2017/index.html","hash":"40535ea8ae95acfc3eb1c6963ba84898dffb599f","modified":1564145943182},{"_id":"public/archives/2017/09/index.html","hash":"95ebc4b45e8fc15d3aed97feac3301506081b59f","modified":1564145943182},{"_id":"public/archives/2019/index.html","hash":"dac263824bf52cc8490d53705d2e6083bc10d09c","modified":1564145943182},{"_id":"public/archives/2019/07/index.html","hash":"819fca1e179acac95114ccdcac9062ba6bb187c7","modified":1564145943182},{"_id":"public/index.html","hash":"a60d9092b8c92e49d85ef00ffc69172dc0858e8d","modified":1564145943182},{"_id":"public/tags/algorithm/index.html","hash":"0aedfb296ba95ce2ee4deb4afa8dc5c3d60baf22","modified":1564145943182},{"_id":"public/tags/optimization/index.html","hash":"a82a916225bb2d9bcbdc45cd1ea353cbbc9900cc","modified":1564145943182},{"_id":"public/tags/EM/index.html","hash":"d4b2285c5ba7efcdfe750ce5b2ca12c468155f35","modified":1564145943182},{"_id":"public/tags/model/index.html","hash":"bf60c23c036c452ad47d8451cf3c75bb349f0900","modified":1564145943182},{"_id":"public/tags/Hexo/index.html","hash":"de923062f237b718f67f88387bce57ae536c5548","modified":1564145943182},{"_id":"public/tags/hexo/index.html","hash":"5f7b513122b72a108ad5435de903a5e74de2a148","modified":1564145943183},{"_id":"public/tags/scripts/index.html","hash":"b9ac574a259313739c2ebfa39a3606c5e93f2872","modified":1564145943183},{"_id":"public/tags/awk/index.html","hash":"894a741913c657416051a6c21b5d82e8e0d9c876","modified":1564145943183},{"_id":"public/CNAME","hash":"947ea2d717f53e46b49eb7f5fcef6d16b58bd86e","modified":1564145943188},{"_id":"public/img/icon_wechat.png","hash":"4188058026609de06c6cac88b349a2da831a1783","modified":1564145943188},{"_id":"public/img/article/tag.png","hash":"c8632d64d9471009098b84f70273e63037a4e7b8","modified":1564145943188},{"_id":"public/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1564145943188},{"_id":"public/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1564145943188},{"_id":"public/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1564145943188},{"_id":"public/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1564145943188},{"_id":"public/css/images/ironman.png","hash":"2f0db0ab15d466c4065d9f6102fdf829726d9e3f","modified":1564145943188},{"_id":"public/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1564145943188},{"_id":"public/css/images/up-arrow.png","hash":"34559d16cb6160e87ff319fe7576a0d16c4e11ff","modified":1564145943189},{"_id":"public/pdfs/jensen_inequality.pdf","hash":"7aee3e40611d8e31808a44b555199bc0fe0c09e8","modified":1564145943336},{"_id":"public/img/header_img/Iron-Man-3.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1564145943336},{"_id":"public/img/header_img/about.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1564145943336},{"_id":"public/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1564145943336},{"_id":"public/css/archive.css","hash":"8db895ebaeff19ac145c961abcfd5d4a8d67a8ea","modified":1564145943343},{"_id":"public/css/donate.css","hash":"f65ac8363d8d215adb896158e7b45165db259a47","modified":1564145943344},{"_id":"public/css/highlight.css","hash":"c58b4569c086e477a00dcbf5a95a166fe5fecfb0","modified":1564145943344},{"_id":"public/css/rocket.css","hash":"c87e8e5d5a9e55eebcdef92e36310e6d0f69ff0b","modified":1564145943344},{"_id":"public/css/signature.css","hash":"820fa4743cea34a61808cd8f7de528605c32d7e3","modified":1564145943344},{"_id":"public/css/toc.css","hash":"f756b9e1b2208d2e5b0f3d2ac5e4fea3b7da0e10","modified":1564145943344},{"_id":"public/css/widget.css","hash":"da95ad3f1938f24d20f1fa77d7a38f0c392b5ec8","modified":1564145943344},{"_id":"public/js/click_show_text.js","hash":"1d4da8ff7daf10a99a197292c3948731c8362eca","modified":1564145943344},{"_id":"public/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1564145943344},{"_id":"public/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1564145943345},{"_id":"public/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1564145943345},{"_id":"public/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1564145943345},{"_id":"public/js/toc.js","hash":"41e52551731854224c249d53010c1bae5aa92ffa","modified":1564145943345},{"_id":"public/js/tagsCloud.js","hash":"453b31fd6d6bb3e5b405b5729ec328ab760c2bef","modified":1564145943346},{"_id":"public/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1564145943346},{"_id":"public/img/404-bg.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1564145943352},{"_id":"public/js/smoothscroll.js","hash":"134a1ad40b68efec27575a2cdd48eccf8a63bf71","modified":1564145943352},{"_id":"public/img/header_img/archives-widget.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1564145943364},{"_id":"public/img/signature/BeanTechSign-white.png","hash":"34289ed41cf9ddac2d56be46fbb1515b7d5913cd","modified":1564145943352},{"_id":"public/img/header_img/tf-logo-dark.png","hash":"5c7bf8ade9de134f8c77a3c59e575abe9fc6cdd4","modified":1564145943352},{"_id":"public/css/beantech.min.css","hash":"05a06230b1a9eca0b30cece54a397008cb77dc50","modified":1564145943357},{"_id":"public/css/beantech.css","hash":"4c361354fd8e9851923fb21a620bc079380ebcd8","modified":1564145943357},{"_id":"public/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1564145943357},{"_id":"public/img/header_img/archive.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1564145943346},{"_id":"public/img/ironman-draw.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1564145943365},{"_id":"public/img/article_header/article_bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1564145943357},{"_id":"public/img/avatar/ironman.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1564145943357},{"_id":"public/img/signature/BeanTechSign-black.png","hash":"94b7102e819fd6ee082d3fb0166f4de7458c22ff","modified":1564145943357},{"_id":"public/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1564145943371},{"_id":"public/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1564145943364},{"_id":"public/img/article/huweihuang_blog.png","hash":"392cf8b33be6c752dd908e027fa3346a6ecd58ab","modified":1564145943387},{"_id":"public/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1564145943392},{"_id":"public/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1564145943398},{"_id":"public/img/header_img/home.jpg","hash":"8f1c440427a4aa86b623503a926c027e2e10cd66","modified":1564145943401},{"_id":"public/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1564145943409},{"_id":"public/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1564145943414},{"_id":"public/img/header_img/tag.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1564145943423},{"_id":"public/img/header_img/tag-bg.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1564145943423},{"_id":"public/img/beantech-desktop.png","hash":"4a8f8b209c9db8fd5209f15b8e4590525e258b0f","modified":1564145943430},{"_id":"public/article/GMM/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1564145943439},{"_id":"public/article/EM/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1564145943437},{"_id":"public/article/HMM/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1564145943437},{"_id":"public/article/hexo-theme-huweihuang/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1564145943440},{"_id":"public/article/scripts/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1564145943441},{"_id":"public/img/article_header/article_header.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1564145943441},{"_id":"public/img/header_img/home-bg-o.png","hash":"134ece4cb4c49c7ca1403a5afe7f46d0e2f9ecbb","modified":1564145943447},{"_id":"public/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1564145943455},{"_id":"public/img/header_img/home2.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1564145943460},{"_id":"public/img/header_img/home-bg-2-dark.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1564145943460},{"_id":"public/img/header_img/404.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1564145943480},{"_id":"public/img/header_img/archive-bg.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1564145943477}],"Category":[],"Data":[],"Page":[{"layout":"404","description":"你来到了没有知识的荒原 :(","header-img":"img/404-bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"你来到了没有知识的荒原 :(\"\nheader-img: \"img/404-bg.jpg\"\n---\n","date":"2019-07-16T02:04:41.424Z","updated":"2019-07-13T11:25:24.390Z","path":"404.html","title":"","comments":1,"_id":"cjyiirp4d0000o8he4n6rteto","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"about","title":"About","date":"2016-04-20T20:48:33.000Z","description":"Wish for the Best, Prepare for the Worst","header-img":"img/header_img/Iron-Man-3.jpg","comments":1,"_content":"\n> 光有好奇心而不去實踐，等於自願放棄成功機會\n> 別為自己畫地自限，Just Do It！！\n","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"About\"\ndate: 2016-04-21 04:48:33\ndescription: \"Wish for the Best, Prepare for the Worst\"\nheader-img: \"img/header_img/Iron-Man-3.jpg\"\ncomments: true\n---\n\n> 光有好奇心而不去實踐，等於自願放棄成功機會\n> 別為自己畫地自限，Just Do It！！\n","updated":"2019-07-13T11:25:24.422Z","path":"about/index.html","_id":"cjyiirp570002o8he83piuso7","content":"<blockquote>\n<p>光有好奇心而不去實踐，等於自願放棄成功機會<br>別為自己畫地自限，Just Do It！！</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>光有好奇心而不去實踐，等於自願放棄成功機會<br>別為自己畫地自限，Just Do It！！</p>\n</blockquote>\n"},{"layout":"tags","title":"Tags","description":"Hey, this is Tags.","header-img":"img/header_img/tag-bg.png","_content":"","source":"tags/index.md","raw":"---\nlayout: \"tags\"\ntitle: \"Tags\"\ndescription: \"Hey, this is Tags.\"\nheader-img: \"img/header_img/tag-bg.png\"\n---\n","date":"2019-07-16T02:04:41.460Z","updated":"2019-07-13T11:25:24.690Z","path":"tags/index.html","comments":1,"_id":"cjyiirp5a0004o8hes6gxl1vz","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"archive","title":"Archives","header-img":"img/header_img/archive-bg.png","comments":0,"date":"2017-03-20T12:49:56.000Z","description":"Hey, this is archives","_content":"","source":"archive/index.md","raw":"---\nlayout: \"archive\"\ntitle: \"Archives\"\nheader-img: \"img/header_img/archive-bg.png\"\ncomments: false\ndate: 2017-03-20 20:49:56\ndescription: \"Hey, this is archives\"\n---\n","updated":"2019-07-13T11:25:24.422Z","path":"archive/index.html","_id":"cjyiirp5d0007o8he372m6xf2","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"[Algorithm] EM algorithm","catalog":true,"toc_nav_num":true,"date":"2019-07-16T03:08:59.000Z","subtitle":"EM algorithm derivation","header-img":"Demo.png","top":1,"mathjax":true,"catagories":["algorithm"],"_content":"\n> 本文记录了EM算法的思想及其推导过程, 仍然感觉自己对EM算法的本质理解有所欠缺，以后补充\n\n## 介绍\n> The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly. Typically these models involve latent variables in addition to unknown parameters and known data observations. That is, either missing values exist among the data, or the model can be formulated more simply by assuming the existence of further unobserved data points.  \n[https://en.wikipedia.org/wiki/Expectation-maximization_algorithm]\n\n<!-- -->\n> 对于最大似然式无法被直接优化的统计模型, EM算法的目的是找到其局部最优参数解。这样的模型通常涉及**隐变量 ($Z$)、未知参数 ($\\theta$) 以及可观测的数据 ($Y$) **。EM算法可以解决两类问题:  \n1. 数据缺失的问题: 在缺失部分数据的情况下建模。  \n2. 模型存在隐变量: 通过进一步定义不可观测的隐变量, 可以使模型更加简单(似然式更加简单)。\n\n## 算法推导\n\n### 似然函数\n对于一个含有隐变量 $Z$ 的模型，目的是极大化观测数据 $Y$ 关于参数 $\\theta$ 的对数似然函数, 即:\n$$\n\\mathcal{L}(\\theta) =\\log P(Y\\mathrel|\\theta) = \\log \\sum_Z P(Y,Z \\mathrel | \\theta) \n$$\n---\n\n#### 似然函数的下界\n通过构造Jensen不等式，可以得到似然函数的下界函数:\n$$\n\\begin{align}\n\\mathcal{L}(\\theta) &= \\log \\sum_Z P(Y,Z \\mathrel | \\theta) \\\\\n                    &= \\log \\sum_Z (Q(Z) \\cdot \\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)}) \\\\\n                    &\\ge \\sum_Z (Q(Z) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)})) \\\\\n                    &= \\mathcal{H}(\\theta, Q(Z))\n\\end{align}\\label{eq:1}\\tag{1} \n$$\n构造Jensen不等式要求 $Q(Z)$ 满足 $\\sum_Z Q(Z)=1$, 因此它可以视为 $Z$ 的某个概率分布函数.\n\n---\n### 如何优化似然函数\n为了优化似然函数$\\mathcal{L}(\\theta)$, 需要解决两个问题:\n**[1] 为什么优化 $\\mathcal{H}(\\theta, Q(Z))$, 等价于优化 $\\mathcal{L}(\\theta)$ ?**\n**[2] 如何优化 $\\mathcal{H}(\\theta, Q(Z))$ ?** \n\n---\n\n#### 为何优化下界函数\n我们希望通过优化$\\mathcal{H}(\\theta, Q(Z))$, 来优化$\\mathcal{L}(\\theta)$，即:\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) > \\mathcal{L}(\\hat{\\theta}) \\label{eq:2}\\tag{2}\n\\end{align}\n而根据Jensen不等式，我们现在有：\n$$\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) \\ge \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\le \\mathcal{L}(\\hat{\\theta})\n\\end{align}\\label{eq:3}\\tag{3}\n$$ \n\n因此要使 Eq.(\\ref{eq:2}) 成立，只需 $\\mathcal{H}(\\hat{\\theta}, Q(Z)) = \\mathcal{L}(\\hat{\\theta})$, 即Jensen不等式 Eq.(\\ref{eq:1}) 在 $\\theta=\\hat{\\theta}$ 处取等, 根据Jensen不等式的取等条件, 有:\n\n\\begin{align}\n\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{Q(Z)}             &= constant \\\\\n\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}         &= Q(Z) \\label{eq:4}\\tag{4} \\\\\n\\sum_Z \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}  &= \\sum_Z Q(Z)=1 \\\\\n\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})                   &= constant \\label{eq:5}\\tag{5} \\\\\n\\end{align}\n将 Eq.(\\ref{eq:5}) 代入 Eq.(\\ref{eq:4}), 得到 $Q(Z)$ 的表达式:\n\\begin{aligned}\nQ(Z)    &= \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})} \\\\\n        &= P(Z \\mathrel | Y, \\hat{\\theta})\n\\end{aligned}\n\n即:\n$$\n\\begin{align}\n\\text{if and only if: } & Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta}) \\\\\n\\text{then: } & L(\\hat{\\theta}) = H(\\hat{\\theta}, Q(Z))  \\\\\n\\text{otherwise: } & L(\\hat{\\theta}) > H(\\hat{\\theta}, Q(Z))\n\\end{align}\\label{eq:6}\\tag{6}\n$$\n\n---\n\n根据 Eq.(\\ref{eq:3}) 和 Eq.(\\ref{eq:6}), 我们得到如下结论:\n\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) > \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) > \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) = \\mathcal{L}(\\hat{\\theta})\n\\end{align}\n\n> **即, 在似然函数的参数 $\\theta = \\hat{\\theta}$ 处, 取下界函数 $H(\\hat{\\theta}, Q(Z))$ 的参数 $Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta})$ 时，优化下界函数 $\\mathcal{H}(\\hat{\\theta}, Q(Z))$ 等价于优化似然函数 $\\mathcal{L}(\\hat{\\theta})$。**\n\n---\n\n#### 如何优化下界函数\n\n根据 Eq.(\\ref{eq:6}):\n$$\n\\begin{align}\n& \\forall \\hat{\\theta} \\neq \\bar{\\theta} \\\\\n\\because & \\mathcal{L(\\bar{\\theta})} = \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) \\\\\n& \\mathcal{L(\\bar{\\theta})} > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n\\therefore & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:7}\\tag{7}\n$$\n\n---\n又:\n$$\n\\begin{align}\n\\forall \\hat{\\theta},  \\exists \\bar{\\theta} &= \\underset{\\theta}{\\mathrm{argmax}}\\ \\mathcal{H}(\\theta, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{P(Z \\mathrel | Y, \\hat{\\theta})})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (P(Y,Z \\mathrel | \\theta))) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ E_{Z\\sim P(Z \\mathrel | Y, \\hat{\\theta})} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\\ns.t.\\  & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\ge \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:8}\\tag{8}\n$$\n\n根据 Eq.(\\ref{eq:7}) 和 Eq.(\\ref{eq:8}),对于初值 $\\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0))$, 我们可以通过这样的迭代过程优化它: \n$$\n\\begin{align}\n& \\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0)) \\le \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_0)) \\\\\n< &\\ \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_1)) \\le \\mathcal{H}(\\theta_2, P(Z \\mathrel | Y, \\theta_1)) \\\\\n< &\\ \\cdots\n\\end{align}\\label{eq:9}\\tag{9}\n$$\n在 $\\mathcal{H}(\\theta_{n+1}, P(Z \\mathrel | Y, \\theta_{n}))=\\mathcal{H}(\\theta_{n}, P(Z \\mathrel | Y, \\theta_{n}))$ 时收敛。\n\n---\n\n## 算法流程\n\nEq.(\\ref{eq:9}) 的迭代中包含了两个优化过程: 一个是 Eq.(\\ref{eq:7})，另一个是 Eq.(\\ref{eq:8})。而 Eq.(\\ref{eq:7}) 的过程是简单的将下界函数  $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i}))$ 替换为 $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i+1}))$ 。因此, EM算法的流程指的是 Eq.(\\ref{eq:8}) 的优化 (即产生 $\\theta_{i+1}$ 的过程)。\n\n### E步\n\n根据当前的 $\\hat{\\theta}$ 写出 Eq.(\\ref{eq:8}) 的优化目标:\n$$\nJ(\\theta) = E_{Z\\sim P(Z \\mathrel | Y, \\theta_i)} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\\n$$\n\n### M步\n\n对 $J(\\theta)$ 关于 $\\theta$ 求导等于0, 得到 $\\theta_{i+1}$:\n$$\n\\theta_{i+1} = \\underset{\\theta}{\\mathrm{argmax}}\\ J(\\theta) \\\\\n\\frac{d J(\\theta)}{d \\theta} = 0  \\Rightarrow  \\theta = \\theta_{i+1}\n$$\n\n---\n\n\n## 相关链接\n\n- [EM算法的应用: GMM](/article/GMM)\n- [EM算法的应用: HMM](/article/HMM)\n- [Jensen 不等式的证明 - 数学归纳法](/pdfs/jensen_inequality.pdf)\n","source":"_posts/EM.md","raw":"---\ntitle: \"[Algorithm] EM algorithm\"\ncatalog: true\ntoc_nav_num: true\ndate: 2019-07-16 11:08:59\nsubtitle: \"EM algorithm derivation\"\nheader-img: \"Demo.png\"\ntop: 1\ntags:\n- algorithm\n- optimization\n- EM\nmathjax: true\ncatagories:\n- algorithm\n---\n\n> 本文记录了EM算法的思想及其推导过程, 仍然感觉自己对EM算法的本质理解有所欠缺，以后补充\n\n## 介绍\n> The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly. Typically these models involve latent variables in addition to unknown parameters and known data observations. That is, either missing values exist among the data, or the model can be formulated more simply by assuming the existence of further unobserved data points.  \n[https://en.wikipedia.org/wiki/Expectation-maximization_algorithm]\n\n<!-- -->\n> 对于最大似然式无法被直接优化的统计模型, EM算法的目的是找到其局部最优参数解。这样的模型通常涉及**隐变量 ($Z$)、未知参数 ($\\theta$) 以及可观测的数据 ($Y$) **。EM算法可以解决两类问题:  \n1. 数据缺失的问题: 在缺失部分数据的情况下建模。  \n2. 模型存在隐变量: 通过进一步定义不可观测的隐变量, 可以使模型更加简单(似然式更加简单)。\n\n## 算法推导\n\n### 似然函数\n对于一个含有隐变量 $Z$ 的模型，目的是极大化观测数据 $Y$ 关于参数 $\\theta$ 的对数似然函数, 即:\n$$\n\\mathcal{L}(\\theta) =\\log P(Y\\mathrel|\\theta) = \\log \\sum_Z P(Y,Z \\mathrel | \\theta) \n$$\n---\n\n#### 似然函数的下界\n通过构造Jensen不等式，可以得到似然函数的下界函数:\n$$\n\\begin{align}\n\\mathcal{L}(\\theta) &= \\log \\sum_Z P(Y,Z \\mathrel | \\theta) \\\\\n                    &= \\log \\sum_Z (Q(Z) \\cdot \\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)}) \\\\\n                    &\\ge \\sum_Z (Q(Z) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)})) \\\\\n                    &= \\mathcal{H}(\\theta, Q(Z))\n\\end{align}\\label{eq:1}\\tag{1} \n$$\n构造Jensen不等式要求 $Q(Z)$ 满足 $\\sum_Z Q(Z)=1$, 因此它可以视为 $Z$ 的某个概率分布函数.\n\n---\n### 如何优化似然函数\n为了优化似然函数$\\mathcal{L}(\\theta)$, 需要解决两个问题:\n**[1] 为什么优化 $\\mathcal{H}(\\theta, Q(Z))$, 等价于优化 $\\mathcal{L}(\\theta)$ ?**\n**[2] 如何优化 $\\mathcal{H}(\\theta, Q(Z))$ ?** \n\n---\n\n#### 为何优化下界函数\n我们希望通过优化$\\mathcal{H}(\\theta, Q(Z))$, 来优化$\\mathcal{L}(\\theta)$，即:\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) > \\mathcal{L}(\\hat{\\theta}) \\label{eq:2}\\tag{2}\n\\end{align}\n而根据Jensen不等式，我们现在有：\n$$\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) \\ge \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\le \\mathcal{L}(\\hat{\\theta})\n\\end{align}\\label{eq:3}\\tag{3}\n$$ \n\n因此要使 Eq.(\\ref{eq:2}) 成立，只需 $\\mathcal{H}(\\hat{\\theta}, Q(Z)) = \\mathcal{L}(\\hat{\\theta})$, 即Jensen不等式 Eq.(\\ref{eq:1}) 在 $\\theta=\\hat{\\theta}$ 处取等, 根据Jensen不等式的取等条件, 有:\n\n\\begin{align}\n\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{Q(Z)}             &= constant \\\\\n\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}         &= Q(Z) \\label{eq:4}\\tag{4} \\\\\n\\sum_Z \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}  &= \\sum_Z Q(Z)=1 \\\\\n\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})                   &= constant \\label{eq:5}\\tag{5} \\\\\n\\end{align}\n将 Eq.(\\ref{eq:5}) 代入 Eq.(\\ref{eq:4}), 得到 $Q(Z)$ 的表达式:\n\\begin{aligned}\nQ(Z)    &= \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})} \\\\\n        &= P(Z \\mathrel | Y, \\hat{\\theta})\n\\end{aligned}\n\n即:\n$$\n\\begin{align}\n\\text{if and only if: } & Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta}) \\\\\n\\text{then: } & L(\\hat{\\theta}) = H(\\hat{\\theta}, Q(Z))  \\\\\n\\text{otherwise: } & L(\\hat{\\theta}) > H(\\hat{\\theta}, Q(Z))\n\\end{align}\\label{eq:6}\\tag{6}\n$$\n\n---\n\n根据 Eq.(\\ref{eq:3}) 和 Eq.(\\ref{eq:6}), 我们得到如下结论:\n\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) > \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) > \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) = \\mathcal{L}(\\hat{\\theta})\n\\end{align}\n\n> **即, 在似然函数的参数 $\\theta = \\hat{\\theta}$ 处, 取下界函数 $H(\\hat{\\theta}, Q(Z))$ 的参数 $Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta})$ 时，优化下界函数 $\\mathcal{H}(\\hat{\\theta}, Q(Z))$ 等价于优化似然函数 $\\mathcal{L}(\\hat{\\theta})$。**\n\n---\n\n#### 如何优化下界函数\n\n根据 Eq.(\\ref{eq:6}):\n$$\n\\begin{align}\n& \\forall \\hat{\\theta} \\neq \\bar{\\theta} \\\\\n\\because & \\mathcal{L(\\bar{\\theta})} = \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) \\\\\n& \\mathcal{L(\\bar{\\theta})} > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n\\therefore & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:7}\\tag{7}\n$$\n\n---\n又:\n$$\n\\begin{align}\n\\forall \\hat{\\theta},  \\exists \\bar{\\theta} &= \\underset{\\theta}{\\mathrm{argmax}}\\ \\mathcal{H}(\\theta, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{P(Z \\mathrel | Y, \\hat{\\theta})})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (P(Y,Z \\mathrel | \\theta))) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ E_{Z\\sim P(Z \\mathrel | Y, \\hat{\\theta})} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\\ns.t.\\  & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\ge \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:8}\\tag{8}\n$$\n\n根据 Eq.(\\ref{eq:7}) 和 Eq.(\\ref{eq:8}),对于初值 $\\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0))$, 我们可以通过这样的迭代过程优化它: \n$$\n\\begin{align}\n& \\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0)) \\le \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_0)) \\\\\n< &\\ \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_1)) \\le \\mathcal{H}(\\theta_2, P(Z \\mathrel | Y, \\theta_1)) \\\\\n< &\\ \\cdots\n\\end{align}\\label{eq:9}\\tag{9}\n$$\n在 $\\mathcal{H}(\\theta_{n+1}, P(Z \\mathrel | Y, \\theta_{n}))=\\mathcal{H}(\\theta_{n}, P(Z \\mathrel | Y, \\theta_{n}))$ 时收敛。\n\n---\n\n## 算法流程\n\nEq.(\\ref{eq:9}) 的迭代中包含了两个优化过程: 一个是 Eq.(\\ref{eq:7})，另一个是 Eq.(\\ref{eq:8})。而 Eq.(\\ref{eq:7}) 的过程是简单的将下界函数  $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i}))$ 替换为 $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i+1}))$ 。因此, EM算法的流程指的是 Eq.(\\ref{eq:8}) 的优化 (即产生 $\\theta_{i+1}$ 的过程)。\n\n### E步\n\n根据当前的 $\\hat{\\theta}$ 写出 Eq.(\\ref{eq:8}) 的优化目标:\n$$\nJ(\\theta) = E_{Z\\sim P(Z \\mathrel | Y, \\theta_i)} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\\n$$\n\n### M步\n\n对 $J(\\theta)$ 关于 $\\theta$ 求导等于0, 得到 $\\theta_{i+1}$:\n$$\n\\theta_{i+1} = \\underset{\\theta}{\\mathrm{argmax}}\\ J(\\theta) \\\\\n\\frac{d J(\\theta)}{d \\theta} = 0  \\Rightarrow  \\theta = \\theta_{i+1}\n$$\n\n---\n\n\n## 相关链接\n\n- [EM算法的应用: GMM](/article/GMM)\n- [EM算法的应用: HMM](/article/HMM)\n- [Jensen 不等式的证明 - 数学归纳法](/pdfs/jensen_inequality.pdf)\n","slug":"EM","published":1,"updated":"2019-07-23T06:00:57.751Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyiirp540001o8hemqrbxyjh","content":"<blockquote>\n<p>本文记录了EM算法的思想及其推导过程, 仍然感觉自己对EM算法的本质理解有所欠缺，以后补充</p>\n</blockquote>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><blockquote>\n<p>The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly. Typically these models involve latent variables in addition to unknown parameters and known data observations. That is, either missing values exist among the data, or the model can be formulated more simply by assuming the existence of further unobserved data points.<br>[<a href=\"https://en.wikipedia.org/wiki/Expectation-maximization_algorithm\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Expectation-maximization_algorithm</a>]</p>\n</blockquote>\n<!-- -->\n<blockquote>\n<p>对于最大似然式无法被直接优化的统计模型, EM算法的目的是找到其局部最优参数解。这样的模型通常涉及<strong>隐变量 ($Z$)、未知参数 ($\\theta$) 以及可观测的数据 ($Y$) </strong>。EM算法可以解决两类问题:  </p>\n<ol>\n<li>数据缺失的问题: 在缺失部分数据的情况下建模。  </li>\n<li>模型存在隐变量: 通过进一步定义不可观测的隐变量, 可以使模型更加简单(似然式更加简单)。</li>\n</ol>\n</blockquote>\n<h2 id=\"算法推导\"><a href=\"#算法推导\" class=\"headerlink\" title=\"算法推导\"></a>算法推导</h2><h3 id=\"似然函数\"><a href=\"#似然函数\" class=\"headerlink\" title=\"似然函数\"></a>似然函数</h3><p>对于一个含有隐变量 $Z$ 的模型，目的是极大化观测数据 $Y$ 关于参数 $\\theta$ 的对数似然函数, 即:</p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L}(\\theta) =\\log P(Y\\mathrel|\\theta) = \\log \\sum_Z P(Y,Z \\mathrel | \\theta)</script><hr>\n<h4 id=\"似然函数的下界\"><a href=\"#似然函数的下界\" class=\"headerlink\" title=\"似然函数的下界\"></a>似然函数的下界</h4><p>通过构造Jensen不等式，可以得到似然函数的下界函数:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\mathcal{L}(\\theta) &= \\log \\sum_Z P(Y,Z \\mathrel | \\theta) \\\\\n                    &= \\log \\sum_Z (Q(Z) \\cdot \\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)}) \\\\\n                    &\\ge \\sum_Z (Q(Z) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)})) \\\\\n                    &= \\mathcal{H}(\\theta, Q(Z))\n\\end{align}\\label{eq:1}\\tag{1}</script><p>构造Jensen不等式要求 $Q(Z)$ 满足 $\\sum_Z Q(Z)=1$, 因此它可以视为 $Z$ 的某个概率分布函数.</p>\n<hr>\n<h3 id=\"如何优化似然函数\"><a href=\"#如何优化似然函数\" class=\"headerlink\" title=\"如何优化似然函数\"></a>如何优化似然函数</h3><p>为了优化似然函数$\\mathcal{L}(\\theta)$, 需要解决两个问题:<br><strong>[1] 为什么优化 $\\mathcal{H}(\\theta, Q(Z))$, 等价于优化 $\\mathcal{L}(\\theta)$ ?</strong><br><strong>[2] 如何优化 $\\mathcal{H}(\\theta, Q(Z))$ ?</strong> </p>\n<hr>\n<h4 id=\"为何优化下界函数\"><a href=\"#为何优化下界函数\" class=\"headerlink\" title=\"为何优化下界函数\"></a>为何优化下界函数</h4><p>我们希望通过优化$\\mathcal{H}(\\theta, Q(Z))$, 来优化$\\mathcal{L}(\\theta)$，即:<br>\\begin{align}<br>\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\<br>\\text{ if } &amp;  \\\\<br>&amp; \\mathcal{H}(\\bar{\\theta}, Q(Z)) &gt; \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\<br>\\text{then }&amp;  \\\\<br>&amp; \\mathcal{L}(\\bar{\\theta}) &gt; \\mathcal{L}(\\hat{\\theta}) \\label{eq:2}\\tag{2}<br>\\end{align}<br>而根据Jensen不等式，我们现在有：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) \\ge \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\le \\mathcal{L}(\\hat{\\theta})\n\\end{align}\\label{eq:3}\\tag{3}</script><p>因此要使 Eq.(\\ref{eq:2}) 成立，只需 $\\mathcal{H}(\\hat{\\theta}, Q(Z)) = \\mathcal{L}(\\hat{\\theta})$, 即Jensen不等式 Eq.(\\ref{eq:1}) 在 $\\theta=\\hat{\\theta}$ 处取等, 根据Jensen不等式的取等条件, 有:</p>\n<p>\\begin{align}<br>\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{Q(Z)}             &amp;= constant \\\\<br>\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}         &amp;= Q(Z) \\label{eq:4}\\tag{4} \\\\<br>\\sum_Z \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}  &amp;= \\sum_Z Q(Z)=1 \\\\<br>\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})                   &amp;= constant \\label{eq:5}\\tag{5} \\\\<br>\\end{align}<br>将 Eq.(\\ref{eq:5}) 代入 Eq.(\\ref{eq:4}), 得到 $Q(Z)$ 的表达式:<br>\\begin{aligned}<br>Q(Z)    &amp;= \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})} \\\\<br>        &amp;= P(Z \\mathrel | Y, \\hat{\\theta})<br>\\end{aligned}</p>\n<p>即:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\text{if and only if: } & Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta}) \\\\\n\\text{then: } & L(\\hat{\\theta}) = H(\\hat{\\theta}, Q(Z))  \\\\\n\\text{otherwise: } & L(\\hat{\\theta}) > H(\\hat{\\theta}, Q(Z))\n\\end{align}\\label{eq:6}\\tag{6}</script><hr>\n<p>根据 Eq.(\\ref{eq:3}) 和 Eq.(\\ref{eq:6}), 我们得到如下结论:</p>\n<p>\\begin{align}<br>\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\<br>\\text{ if } &amp;  \\\\<br>&amp; \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) &gt; \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\<br>\\text{then }&amp;  \\\\<br>&amp; \\mathcal{L}(\\bar{\\theta}) &gt; \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) &gt; \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) = \\mathcal{L}(\\hat{\\theta})<br>\\end{align}</p>\n<blockquote>\n<p><strong>即, 在似然函数的参数 $\\theta = \\hat{\\theta}$ 处, 取下界函数 $H(\\hat{\\theta}, Q(Z))$ 的参数 $Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta})$ 时，优化下界函数 $\\mathcal{H}(\\hat{\\theta}, Q(Z))$ 等价于优化似然函数 $\\mathcal{L}(\\hat{\\theta})$。</strong></p>\n</blockquote>\n<hr>\n<h4 id=\"如何优化下界函数\"><a href=\"#如何优化下界函数\" class=\"headerlink\" title=\"如何优化下界函数\"></a>如何优化下界函数</h4><p>根据 Eq.(\\ref{eq:6}):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n& \\forall \\hat{\\theta} \\neq \\bar{\\theta} \\\\\n\\because & \\mathcal{L(\\bar{\\theta})} = \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) \\\\\n& \\mathcal{L(\\bar{\\theta})} > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n\\therefore & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:7}\\tag{7}</script><hr>\n<p>又:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\forall \\hat{\\theta},  \\exists \\bar{\\theta} &= \\underset{\\theta}{\\mathrm{argmax}}\\ \\mathcal{H}(\\theta, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{P(Z \\mathrel | Y, \\hat{\\theta})})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (P(Y,Z \\mathrel | \\theta))) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ E_{Z\\sim P(Z \\mathrel | Y, \\hat{\\theta})} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\\ns.t.\\  & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\ge \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:8}\\tag{8}</script><p>根据 Eq.(\\ref{eq:7}) 和 Eq.(\\ref{eq:8}),对于初值 $\\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0))$, 我们可以通过这样的迭代过程优化它: </p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n& \\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0)) \\le \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_0)) \\\\\n< &\\ \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_1)) \\le \\mathcal{H}(\\theta_2, P(Z \\mathrel | Y, \\theta_1)) \\\\\n< &\\ \\cdots\n\\end{align}\\label{eq:9}\\tag{9}</script><p>在 $\\mathcal{H}(\\theta_{n+1}, P(Z \\mathrel | Y, \\theta_{n}))=\\mathcal{H}(\\theta_{n}, P(Z \\mathrel | Y, \\theta_{n}))$ 时收敛。</p>\n<hr>\n<h2 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h2><p>Eq.(\\ref{eq:9}) 的迭代中包含了两个优化过程: 一个是 Eq.(\\ref{eq:7})，另一个是 Eq.(\\ref{eq:8})。而 Eq.(\\ref{eq:7}) 的过程是简单的将下界函数  $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i}))$ 替换为 $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i+1}))$ 。因此, EM算法的流程指的是 Eq.(\\ref{eq:8}) 的优化 (即产生 $\\theta_{i+1}$ 的过程)。</p>\n<h3 id=\"E步\"><a href=\"#E步\" class=\"headerlink\" title=\"E步\"></a>E步</h3><p>根据当前的 $\\hat{\\theta}$ 写出 Eq.(\\ref{eq:8}) 的优化目标:</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta) = E_{Z\\sim P(Z \\mathrel | Y, \\theta_i)} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\</script><h3 id=\"M步\"><a href=\"#M步\" class=\"headerlink\" title=\"M步\"></a>M步</h3><p>对 $J(\\theta)$ 关于 $\\theta$ 求导等于0, 得到 $\\theta_{i+1}$:</p>\n<script type=\"math/tex; mode=display\">\n\\theta_{i+1} = \\underset{\\theta}{\\mathrm{argmax}}\\ J(\\theta) \\\\\n\\frac{d J(\\theta)}{d \\theta} = 0  \\Rightarrow  \\theta = \\theta_{i+1}</script><hr>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"/article/GMM\">EM算法的应用: GMM</a></li>\n<li><a href=\"/article/HMM\">EM算法的应用: HMM</a></li>\n<li><a href=\"/pdfs/jensen_inequality.pdf\">Jensen 不等式的证明 - 数学归纳法</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文记录了EM算法的思想及其推导过程, 仍然感觉自己对EM算法的本质理解有所欠缺，以后补充</p>\n</blockquote>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><blockquote>\n<p>The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly. Typically these models involve latent variables in addition to unknown parameters and known data observations. That is, either missing values exist among the data, or the model can be formulated more simply by assuming the existence of further unobserved data points.<br>[<a href=\"https://en.wikipedia.org/wiki/Expectation-maximization_algorithm\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Expectation-maximization_algorithm</a>]</p>\n</blockquote>\n<!-- -->\n<blockquote>\n<p>对于最大似然式无法被直接优化的统计模型, EM算法的目的是找到其局部最优参数解。这样的模型通常涉及<strong>隐变量 ($Z$)、未知参数 ($\\theta$) 以及可观测的数据 ($Y$) </strong>。EM算法可以解决两类问题:  </p>\n<ol>\n<li>数据缺失的问题: 在缺失部分数据的情况下建模。  </li>\n<li>模型存在隐变量: 通过进一步定义不可观测的隐变量, 可以使模型更加简单(似然式更加简单)。</li>\n</ol>\n</blockquote>\n<h2 id=\"算法推导\"><a href=\"#算法推导\" class=\"headerlink\" title=\"算法推导\"></a>算法推导</h2><h3 id=\"似然函数\"><a href=\"#似然函数\" class=\"headerlink\" title=\"似然函数\"></a>似然函数</h3><p>对于一个含有隐变量 $Z$ 的模型，目的是极大化观测数据 $Y$ 关于参数 $\\theta$ 的对数似然函数, 即:</p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L}(\\theta) =\\log P(Y\\mathrel|\\theta) = \\log \\sum_Z P(Y,Z \\mathrel | \\theta)</script><hr>\n<h4 id=\"似然函数的下界\"><a href=\"#似然函数的下界\" class=\"headerlink\" title=\"似然函数的下界\"></a>似然函数的下界</h4><p>通过构造Jensen不等式，可以得到似然函数的下界函数:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\mathcal{L}(\\theta) &= \\log \\sum_Z P(Y,Z \\mathrel | \\theta) \\\\\n                    &= \\log \\sum_Z (Q(Z) \\cdot \\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)}) \\\\\n                    &\\ge \\sum_Z (Q(Z) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{Q(Z)})) \\\\\n                    &= \\mathcal{H}(\\theta, Q(Z))\n\\end{align}\\label{eq:1}\\tag{1}</script><p>构造Jensen不等式要求 $Q(Z)$ 满足 $\\sum_Z Q(Z)=1$, 因此它可以视为 $Z$ 的某个概率分布函数.</p>\n<hr>\n<h3 id=\"如何优化似然函数\"><a href=\"#如何优化似然函数\" class=\"headerlink\" title=\"如何优化似然函数\"></a>如何优化似然函数</h3><p>为了优化似然函数$\\mathcal{L}(\\theta)$, 需要解决两个问题:<br><strong>[1] 为什么优化 $\\mathcal{H}(\\theta, Q(Z))$, 等价于优化 $\\mathcal{L}(\\theta)$ ?</strong><br><strong>[2] 如何优化 $\\mathcal{H}(\\theta, Q(Z))$ ?</strong> </p>\n<hr>\n<h4 id=\"为何优化下界函数\"><a href=\"#为何优化下界函数\" class=\"headerlink\" title=\"为何优化下界函数\"></a>为何优化下界函数</h4><p>我们希望通过优化$\\mathcal{H}(\\theta, Q(Z))$, 来优化$\\mathcal{L}(\\theta)$，即:<br>\\begin{align}<br>\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\<br>\\text{ if } &amp;  \\\\<br>&amp; \\mathcal{H}(\\bar{\\theta}, Q(Z)) &gt; \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\<br>\\text{then }&amp;  \\\\<br>&amp; \\mathcal{L}(\\bar{\\theta}) &gt; \\mathcal{L}(\\hat{\\theta}) \\label{eq:2}\\tag{2}<br>\\end{align}<br>而根据Jensen不等式，我们现在有：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\\n\\text{ if } &  \\\\\n& \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\\\\n\\text{then }&  \\\\\n& \\mathcal{L}(\\bar{\\theta}) \\ge \\mathcal{H}(\\bar{\\theta}, Q(Z)) > \\mathcal{H}(\\hat{\\theta}, Q(Z)) \\le \\mathcal{L}(\\hat{\\theta})\n\\end{align}\\label{eq:3}\\tag{3}</script><p>因此要使 Eq.(\\ref{eq:2}) 成立，只需 $\\mathcal{H}(\\hat{\\theta}, Q(Z)) = \\mathcal{L}(\\hat{\\theta})$, 即Jensen不等式 Eq.(\\ref{eq:1}) 在 $\\theta=\\hat{\\theta}$ 处取等, 根据Jensen不等式的取等条件, 有:</p>\n<p>\\begin{align}<br>\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{Q(Z)}             &amp;= constant \\\\<br>\\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}         &amp;= Q(Z) \\label{eq:4}\\tag{4} \\\\<br>\\sum_Z \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{constant}  &amp;= \\sum_Z Q(Z)=1 \\\\<br>\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})                   &amp;= constant \\label{eq:5}\\tag{5} \\\\<br>\\end{align}<br>将 Eq.(\\ref{eq:5}) 代入 Eq.(\\ref{eq:4}), 得到 $Q(Z)$ 的表达式:<br>\\begin{aligned}<br>Q(Z)    &amp;= \\frac{P(Y,Z \\mathrel | \\hat{\\theta})}{\\sum_Z P(Y,Z \\mathrel | \\hat{\\theta})} \\\\<br>        &amp;= P(Z \\mathrel | Y, \\hat{\\theta})<br>\\end{aligned}</p>\n<p>即:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\text{if and only if: } & Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta}) \\\\\n\\text{then: } & L(\\hat{\\theta}) = H(\\hat{\\theta}, Q(Z))  \\\\\n\\text{otherwise: } & L(\\hat{\\theta}) > H(\\hat{\\theta}, Q(Z))\n\\end{align}\\label{eq:6}\\tag{6}</script><hr>\n<p>根据 Eq.(\\ref{eq:3}) 和 Eq.(\\ref{eq:6}), 我们得到如下结论:</p>\n<p>\\begin{align}<br>\\forall \\bar{\\theta}, \\hat{\\theta}: \\\\<br>\\text{ if } &amp;  \\\\<br>&amp; \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) &gt; \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\<br>\\text{then }&amp;  \\\\<br>&amp; \\mathcal{L}(\\bar{\\theta}) &gt; \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) &gt; \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) = \\mathcal{L}(\\hat{\\theta})<br>\\end{align}</p>\n<blockquote>\n<p><strong>即, 在似然函数的参数 $\\theta = \\hat{\\theta}$ 处, 取下界函数 $H(\\hat{\\theta}, Q(Z))$ 的参数 $Q(Z) = P(Z \\mathrel | Y, \\hat{\\theta})$ 时，优化下界函数 $\\mathcal{H}(\\hat{\\theta}, Q(Z))$ 等价于优化似然函数 $\\mathcal{L}(\\hat{\\theta})$。</strong></p>\n</blockquote>\n<hr>\n<h4 id=\"如何优化下界函数\"><a href=\"#如何优化下界函数\" class=\"headerlink\" title=\"如何优化下界函数\"></a>如何优化下界函数</h4><p>根据 Eq.(\\ref{eq:6}):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n& \\forall \\hat{\\theta} \\neq \\bar{\\theta} \\\\\n\\because & \\mathcal{L(\\bar{\\theta})} = \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) \\\\\n& \\mathcal{L(\\bar{\\theta})} > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n\\therefore & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\bar{\\theta})) > \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:7}\\tag{7}</script><hr>\n<p>又:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\forall \\hat{\\theta},  \\exists \\bar{\\theta} &= \\underset{\\theta}{\\mathrm{argmax}}\\ \\mathcal{H}(\\theta, P(Z \\mathrel | Y, \\hat{\\theta})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (\\frac{P(Y,Z \\mathrel | \\theta)}{P(Z \\mathrel | Y, \\hat{\\theta})})) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ \\sum_Z (P(Z \\mathrel | Y, \\hat{\\theta}) \\cdot \\log (P(Y,Z \\mathrel | \\theta))) \\\\\n&= \\underset{\\theta}{\\mathrm{argmax}}\\ E_{Z\\sim P(Z \\mathrel | Y, \\hat{\\theta})} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\\ns.t.\\  & \\mathcal{H}(\\bar{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta})) \\ge \\mathcal{H}(\\hat{\\theta}, P(Z \\mathrel | Y, \\hat{\\theta}))\n\\end{align}\\label{eq:8}\\tag{8}</script><p>根据 Eq.(\\ref{eq:7}) 和 Eq.(\\ref{eq:8}),对于初值 $\\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0))$, 我们可以通过这样的迭代过程优化它: </p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n& \\mathcal{H}(\\theta_0, P(Z \\mathrel | Y, \\theta_0)) \\le \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_0)) \\\\\n< &\\ \\mathcal{H}(\\theta_1, P(Z \\mathrel | Y, \\theta_1)) \\le \\mathcal{H}(\\theta_2, P(Z \\mathrel | Y, \\theta_1)) \\\\\n< &\\ \\cdots\n\\end{align}\\label{eq:9}\\tag{9}</script><p>在 $\\mathcal{H}(\\theta_{n+1}, P(Z \\mathrel | Y, \\theta_{n}))=\\mathcal{H}(\\theta_{n}, P(Z \\mathrel | Y, \\theta_{n}))$ 时收敛。</p>\n<hr>\n<h2 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h2><p>Eq.(\\ref{eq:9}) 的迭代中包含了两个优化过程: 一个是 Eq.(\\ref{eq:7})，另一个是 Eq.(\\ref{eq:8})。而 Eq.(\\ref{eq:7}) 的过程是简单的将下界函数  $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i}))$ 替换为 $\\mathcal{H}(\\theta_{i+1}, P(Z \\mathrel | Y, \\theta_{i+1}))$ 。因此, EM算法的流程指的是 Eq.(\\ref{eq:8}) 的优化 (即产生 $\\theta_{i+1}$ 的过程)。</p>\n<h3 id=\"E步\"><a href=\"#E步\" class=\"headerlink\" title=\"E步\"></a>E步</h3><p>根据当前的 $\\hat{\\theta}$ 写出 Eq.(\\ref{eq:8}) 的优化目标:</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta) = E_{Z\\sim P(Z \\mathrel | Y, \\theta_i)} [\\log (P(Y,Z \\mathrel | \\theta)))] \\\\</script><h3 id=\"M步\"><a href=\"#M步\" class=\"headerlink\" title=\"M步\"></a>M步</h3><p>对 $J(\\theta)$ 关于 $\\theta$ 求导等于0, 得到 $\\theta_{i+1}$:</p>\n<script type=\"math/tex; mode=display\">\n\\theta_{i+1} = \\underset{\\theta}{\\mathrm{argmax}}\\ J(\\theta) \\\\\n\\frac{d J(\\theta)}{d \\theta} = 0  \\Rightarrow  \\theta = \\theta_{i+1}</script><hr>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><ul>\n<li><a href=\"/article/GMM\">EM算法的应用: GMM</a></li>\n<li><a href=\"/article/HMM\">EM算法的应用: HMM</a></li>\n<li><a href=\"/pdfs/jensen_inequality.pdf\">Jensen 不等式的证明 - 数学归纳法</a></li>\n</ul>\n"},{"title":"[Model] GMM model","catalog":true,"toc_nav_num":true,"date":"2019-07-22T09:05:15.000Z","subtitle":"GMM model derivation","header-img":"Demo.png","top":0,"mathjax":true,"catagories":["model"],"_content":"\n> 本文记录了GMM模型的基本理论及其EM算法的优化\n\n\n## 概率密度函数\n\n设有随机变量 $X$, 则高斯混合模型的概率密度函数为:\n$$\np(x) = \\sum_{m=1}^k C_m \\mathcal{N}(x \\mathrel | \\mu_k, \\Sigma_k)\n$$\n","source":"_posts/GMM.md","raw":"---\ntitle: \"[Model] GMM model\"\ncatalog: true\ntoc_nav_num: true\ndate: 2019-07-22 17:05:15\nsubtitle: \"GMM model derivation\"\nheader-img: \"Demo.png\"\ntop: 0\ntags:\n- model\n- optimization\n- EM\nmathjax: true\ncatagories:\n- model\n---\n\n> 本文记录了GMM模型的基本理论及其EM算法的优化\n\n\n## 概率密度函数\n\n设有随机变量 $X$, 则高斯混合模型的概率密度函数为:\n$$\np(x) = \\sum_{m=1}^k C_m \\mathcal{N}(x \\mathrel | \\mu_k, \\Sigma_k)\n$$\n","slug":"GMM","published":1,"updated":"2019-07-22T12:48:34.827Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyiirp590003o8he7mjy77iv","content":"<blockquote>\n<p>本文记录了GMM模型的基本理论及其EM算法的优化</p>\n</blockquote>\n<h2 id=\"概率密度函数\"><a href=\"#概率密度函数\" class=\"headerlink\" title=\"概率密度函数\"></a>概率密度函数</h2><p>设有随机变量 $X$, 则高斯混合模型的概率密度函数为:</p>\n<script type=\"math/tex; mode=display\">\np(x) = \\sum_{m=1}^k C_m \\mathcal{N}(x \\mathrel | \\mu_k, \\Sigma_k)</script>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文记录了GMM模型的基本理论及其EM算法的优化</p>\n</blockquote>\n<h2 id=\"概率密度函数\"><a href=\"#概率密度函数\" class=\"headerlink\" title=\"概率密度函数\"></a>概率密度函数</h2><p>设有随机变量 $X$, 则高斯混合模型的概率密度函数为:</p>\n<script type=\"math/tex; mode=display\">\np(x) = \\sum_{m=1}^k C_m \\mathcal{N}(x \\mathrel | \\mu_k, \\Sigma_k)</script>"},{"title":"[Model] HMM model","catalog":true,"toc_nav_num":true,"date":"2019-07-22T09:05:21.000Z","subtitle":"HMM model derivation","header-img":"Demo.png","top":0,"mathjax":true,"catagories":["model"],"_content":"\n> 本文记录了HMM模型的基本理论及其EM算法的优化\n\n### HMM 的组成\n\n** HMM的参数: $ \\lambda = (A, B, \\pi) $**\n\n|           五元组                              |                                                                                   |\n|       -----------                             |                -----------                                                        |\n| $S = {s_1, s_2, \\dots, s_N}$                  |        隐藏状态集合                                                               | \n| $V = {v_1, v_2, \\dots, v_m, \\dots}$           |        观测值集合                                                                 | \n| $A = a_{11}, \\dots, a_{ij}, \\dots, a_{NN}$    |        转移概率矩阵, $\\sum_{j=1}^N a_{ij} = 1$                                    | \n| $B = b_i(v_j)$                                |        发射概率: 隐藏状态 $s_i$ 产生观测值 $v_j$ 的概率                           | \n| $\\pi = \\pi_1, \\pi_2, \\dots, \\pi_n$            |        起始概率: 隐藏状态 $s_i$成为第一个隐藏状态的概率，$\\sum_{i=1}^N \\pi_i = 1$ | \n\n\n|           其它符号                            |                                                                                   |\n|       -----------                             |                -----------                                                        |\n| $q_{t_1}^{t_2}$                               |        从时间$t_1$到$t_2$的隐藏状态序列                                           | \n| $Q = q_1q_2\\dots q_T$                         |        隐藏状态序列, $q_i \\in S$, $q_1^T$                                         | \n| $o_{t_1}^{t_2}$                               |        从时间$t_1$到$t_2$的观测值序列                                             | \n| $O = o_1o_2\\dots o_T$                         |        观测值序列, $o_i \\in V$, $o_1^T$                                           | \n\n\n---\n\n### HMM 的基本假设\n\n1. 马尔科夫假设\n$$\nP(q_i \\mathrel | q_1\\dots q_{i-1}) = P(q_i\\mathrel | q_{i-1})\n$$\n\n2. 观测值独立性假设\n\n$$\nP(o_i \\mathrel | q_1\\dots q_i\\dots q_T, o_1\\dots o_i \\dots o_T) = P(o_i \\mathrel | q_i)\n$$\n\n---\n\n### HMM - 似然 (Likelihood)\n\n对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求观测序列的似然 $P(O \\mathrel | \\lambda)$。  ( 以下省略 $\\lambda$ ) \n\n#### 前向算法 (Forward Algoithm)\n\n令 $ \\alpha_t(i) = P(o_1^t, q_t=S_i)$ , 则似然观测概率的似然可以表示为: \n\n\n\\begin{align}\nP(O)    &= \\sum_{i=1}^N P(o_i^T, q_T=S_i) \\\\\n        &= \\sum_{i=1}^N \\alpha_T(i)\n\\end{align}\n\n##### 前向递归式\n\\begin{align}\n\\alpha_t(i) &=  P(o_1^t, q_t=S_i)\\\\\n            &=  \\sum_{j=1}^N P(o_1^t, q_{t-1}=S_j, q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N \\alpha_{t-1}(j) \\cdot a_{ji} \\cdot b_i(o_t)\n\\end{align}\n\n其中，初值:\n\\begin{align}\n\\alpha_1(i) &= P(o_1, q_1=S_i) \\\\\n            &= P(q_1=S_i) \\cdot P(o_1 \\mathrel | q_1=S_i) \\\\\n            &= \\pi_i \\cdot b_i(o_1) \n\\end{align}\n\n---\n\n### HMM - 解码 (Decoding)\n\n对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求最可能的状态序列 $Q$:\n\\begin{align}\nQ   &= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(Q \\mathrel | Q) \\\\\n    &= \\underset{q_1^T}{\\mathrm{argmax}}\\ \\frac{P(q_1^T, o_1^T)}{P(o_1^T)} \\\\\n    &= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(q_1^T, o_1^T) \n\\end{align}\n\n令:\n$$\n\\delta_i(t) = \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i)\n$$\n\n则 $Q$ 的最后一个状态为:\n$$\n\\begin{align}\nq_T &= \\underset{q_1^{T-1}}{\\mathrm{argmax}}\\ \\max_{i=1}^N P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{T-1}} P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(T)\n\\end{align}\\label{eq:viterbi-last-state}\\tag{1}\n$$\n\n#### Viterbi 算法\n\n##### 递归 (Recursion)\n\n$$\n\\begin{align}\n\\delta_i(t) &= \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_1^{t-1}) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | q_{t-1}) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-2}} \\max_{j=1}^N P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\cdot \\max_{j=1}^N P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot \\max_{q_1^{t-2}} P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\max_{j=1}^N a_{ji} \\cdot \\delta_j(t-1)\n\\end{align}\\label{eq:viterbi-recursion}\\tag{2}\n$$\n\n其中，初值:\n\\begin{align}\n\\delta_i(1) &= P(o_1, q_1=S_i) \\\\\n            &= \\pi_i \\cdot b_i(o_1)  \\\\\n            &= \\alpha_1(i)\n\\end{align}\n\n此时，将递归式 Eq.(\\ref{eq:viterbi-recursion}) 应用到 Eq.(\\ref{eq:viterbi-last-state}) 中可以得到最可能路径的最后一个状态。\n\n##### 回溯 (Traceback)\n已知最可能路径中的第 $t+1$ 个状态 $q_{t+1}^\\*$, 求该路径中的第 $t$ 个状态:\n\n\\begin{align}\nq_t &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+2}^T, q_{t+1}^\\*, q_t=S_i, o_1^T) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^\\*) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\cdot \\max_{q_{t+2}^T} P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^\\*) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^\\* \\mathrel | q_1^{t-1}, q_t=S_i, o_1^t) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^\\* \\mathrel | q_{t-1}) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(t) \\cdot a_{iq_{t+1}^*}\n\\end{align}\n\n---\n\n### HMM - 后验解码 (Posterior Decoding)\n\n对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求时间$t$处的最可能状态:\n\n\\begin{align}\nq_t &= \\underset{i}{\\mathrm{argmax}}\\ P(q_t=S_i \\mathrel | O)  \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \n\\end{align}\n\n令:\n$$\n\\beta_i(t) = P(o_{t+1}^T \\mathrel | q_t=S_i)\n$$\n\n则 $t$ 时间处隐藏状态 $q_t$ 为 $S_i$ 的后验概率可表示为:\n\\begin{align}\nP(q_t=S_i \\mathrel |o_1^T)  &= \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\\n                            &= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i, o_1^t)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)}  \\\\\n                            &= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\\n                            &= \\frac{\\alpha_i(t)\\cdot \\beta_i(t)}{\\sum_{k=1}^N \\alpha_i(k)\\cdot \\beta_i(k)} \\\\\n\\end{align}\n\n#### 后向递归式\n\n\\begin{align}\n\\beta_i(t) &= P(o_{t+1}^T \\mathrel | q_t=S_i) \\\\\n           &= \\sum_{j=1}^N \\frac{P(o_{t+1}^T, q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\\n           &= \\sum_{j=1}^N \\frac{P(o_{t+1}^T \\mathrel |q_t=S_i, q_{t+1}=S_j) \\cdot P(q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\\n           &= \\sum_{j=1}^N P(o_{t+1}^T \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\\n           &= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | o_{t+2}^T, q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\\n           &= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\\n           &= b_j(o_{t+1}) \\cdot \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot a_{ij} \\\\\n\\end{align}\n\n\n---\n\n### HMM - 参数训练 (Parameter Learning)\n\n对于观测序列 $O$, 求HMM参数 $\\lambda=(A, B, \\pi)$ 的最大似然估计:\n\n#### EM 算法\n\n##### E步\n\nEM算法的通用E步期望公式:\n\n\\begin{align}\nH(\\theta, P(Z\\mathrel | Y, \\hat{\\theta})) &= E_{Z\\sim P(Z\\mathrel | Y, \\hat{\\theta})} [\\log P(Y,Z \\mathrel | \\theta)] \\\\\n                        &= \\sum_Z P(Z\\mathrel | Y, \\hat{\\theta}) \\cdot \\log P(Y,Z \\mathrel | \\theta)\n\\end{align}\n\n代入HMM的参数:\n\n\\begin{align}\nH(\\lambda, P(O\\mathrel | Q, \\hat{\\lambda})) &= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log P(O,Q \\mathrel | \\lambda) \\\\\n                                            &= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (P(q_1)\\cdot P(o_1 \\mathrel | q_1)\\prod_{t=2}^T P(q_{t-1} \\mathrel | q_t) \\cdot P(o_1 \\mathrel | q_1)) \\\\\n                                            &= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1}\\cdot b_{q_1}(o_1)\\prod_{t=2}^T a_{q_{t-1}q_{t}} \\cdot b_{q_t}(o_t)) \\\\\n                                            &= (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1})) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=1}^T \\log b_{q_t}(o_t)) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=2}^T \\log a_{q_{t-1}q_{t}})\n\\end{align}\n \n##### M步\n\n\n\n","source":"_posts/HMM.md","raw":"---\ntitle: \"[Model] HMM model\"\ncatalog: true\ntoc_nav_num: true\ndate: 2019-07-22 17:05:21\nsubtitle: \"HMM model derivation\"\nheader-img: \"Demo.png\"\ntop: 0\ntags:\n- model\n- optimization\n- EM\nmathjax: true\ncatagories:\n- model\n---\n\n> 本文记录了HMM模型的基本理论及其EM算法的优化\n\n### HMM 的组成\n\n** HMM的参数: $ \\lambda = (A, B, \\pi) $**\n\n|           五元组                              |                                                                                   |\n|       -----------                             |                -----------                                                        |\n| $S = {s_1, s_2, \\dots, s_N}$                  |        隐藏状态集合                                                               | \n| $V = {v_1, v_2, \\dots, v_m, \\dots}$           |        观测值集合                                                                 | \n| $A = a_{11}, \\dots, a_{ij}, \\dots, a_{NN}$    |        转移概率矩阵, $\\sum_{j=1}^N a_{ij} = 1$                                    | \n| $B = b_i(v_j)$                                |        发射概率: 隐藏状态 $s_i$ 产生观测值 $v_j$ 的概率                           | \n| $\\pi = \\pi_1, \\pi_2, \\dots, \\pi_n$            |        起始概率: 隐藏状态 $s_i$成为第一个隐藏状态的概率，$\\sum_{i=1}^N \\pi_i = 1$ | \n\n\n|           其它符号                            |                                                                                   |\n|       -----------                             |                -----------                                                        |\n| $q_{t_1}^{t_2}$                               |        从时间$t_1$到$t_2$的隐藏状态序列                                           | \n| $Q = q_1q_2\\dots q_T$                         |        隐藏状态序列, $q_i \\in S$, $q_1^T$                                         | \n| $o_{t_1}^{t_2}$                               |        从时间$t_1$到$t_2$的观测值序列                                             | \n| $O = o_1o_2\\dots o_T$                         |        观测值序列, $o_i \\in V$, $o_1^T$                                           | \n\n\n---\n\n### HMM 的基本假设\n\n1. 马尔科夫假设\n$$\nP(q_i \\mathrel | q_1\\dots q_{i-1}) = P(q_i\\mathrel | q_{i-1})\n$$\n\n2. 观测值独立性假设\n\n$$\nP(o_i \\mathrel | q_1\\dots q_i\\dots q_T, o_1\\dots o_i \\dots o_T) = P(o_i \\mathrel | q_i)\n$$\n\n---\n\n### HMM - 似然 (Likelihood)\n\n对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求观测序列的似然 $P(O \\mathrel | \\lambda)$。  ( 以下省略 $\\lambda$ ) \n\n#### 前向算法 (Forward Algoithm)\n\n令 $ \\alpha_t(i) = P(o_1^t, q_t=S_i)$ , 则似然观测概率的似然可以表示为: \n\n\n\\begin{align}\nP(O)    &= \\sum_{i=1}^N P(o_i^T, q_T=S_i) \\\\\n        &= \\sum_{i=1}^N \\alpha_T(i)\n\\end{align}\n\n##### 前向递归式\n\\begin{align}\n\\alpha_t(i) &=  P(o_1^t, q_t=S_i)\\\\\n            &=  \\sum_{j=1}^N P(o_1^t, q_{t-1}=S_j, q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &=  \\sum_{j=1}^N \\alpha_{t-1}(j) \\cdot a_{ji} \\cdot b_i(o_t)\n\\end{align}\n\n其中，初值:\n\\begin{align}\n\\alpha_1(i) &= P(o_1, q_1=S_i) \\\\\n            &= P(q_1=S_i) \\cdot P(o_1 \\mathrel | q_1=S_i) \\\\\n            &= \\pi_i \\cdot b_i(o_1) \n\\end{align}\n\n---\n\n### HMM - 解码 (Decoding)\n\n对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求最可能的状态序列 $Q$:\n\\begin{align}\nQ   &= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(Q \\mathrel | Q) \\\\\n    &= \\underset{q_1^T}{\\mathrm{argmax}}\\ \\frac{P(q_1^T, o_1^T)}{P(o_1^T)} \\\\\n    &= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(q_1^T, o_1^T) \n\\end{align}\n\n令:\n$$\n\\delta_i(t) = \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i)\n$$\n\n则 $Q$ 的最后一个状态为:\n$$\n\\begin{align}\nq_T &= \\underset{q_1^{T-1}}{\\mathrm{argmax}}\\ \\max_{i=1}^N P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{T-1}} P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(T)\n\\end{align}\\label{eq:viterbi-last-state}\\tag{1}\n$$\n\n#### Viterbi 算法\n\n##### 递归 (Recursion)\n\n$$\n\\begin{align}\n\\delta_i(t) &= \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_1^{t-1}) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | q_{t-1}) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-2}} \\max_{j=1}^N P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\cdot \\max_{j=1}^N P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot \\max_{q_1^{t-2}} P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\max_{j=1}^N a_{ji} \\cdot \\delta_j(t-1)\n\\end{align}\\label{eq:viterbi-recursion}\\tag{2}\n$$\n\n其中，初值:\n\\begin{align}\n\\delta_i(1) &= P(o_1, q_1=S_i) \\\\\n            &= \\pi_i \\cdot b_i(o_1)  \\\\\n            &= \\alpha_1(i)\n\\end{align}\n\n此时，将递归式 Eq.(\\ref{eq:viterbi-recursion}) 应用到 Eq.(\\ref{eq:viterbi-last-state}) 中可以得到最可能路径的最后一个状态。\n\n##### 回溯 (Traceback)\n已知最可能路径中的第 $t+1$ 个状态 $q_{t+1}^\\*$, 求该路径中的第 $t$ 个状态:\n\n\\begin{align}\nq_t &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+2}^T, q_{t+1}^\\*, q_t=S_i, o_1^T) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^\\*) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\cdot \\max_{q_{t+2}^T} P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^\\*) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^\\*, q_t=S_i, o_1^t) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^\\* \\mathrel | q_1^{t-1}, q_t=S_i, o_1^t) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^\\* \\mathrel | q_{t-1}) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(t) \\cdot a_{iq_{t+1}^*}\n\\end{align}\n\n---\n\n### HMM - 后验解码 (Posterior Decoding)\n\n对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求时间$t$处的最可能状态:\n\n\\begin{align}\nq_t &= \\underset{i}{\\mathrm{argmax}}\\ P(q_t=S_i \\mathrel | O)  \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \n\\end{align}\n\n令:\n$$\n\\beta_i(t) = P(o_{t+1}^T \\mathrel | q_t=S_i)\n$$\n\n则 $t$ 时间处隐藏状态 $q_t$ 为 $S_i$ 的后验概率可表示为:\n\\begin{align}\nP(q_t=S_i \\mathrel |o_1^T)  &= \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\\n                            &= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i, o_1^t)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)}  \\\\\n                            &= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\\n                            &= \\frac{\\alpha_i(t)\\cdot \\beta_i(t)}{\\sum_{k=1}^N \\alpha_i(k)\\cdot \\beta_i(k)} \\\\\n\\end{align}\n\n#### 后向递归式\n\n\\begin{align}\n\\beta_i(t) &= P(o_{t+1}^T \\mathrel | q_t=S_i) \\\\\n           &= \\sum_{j=1}^N \\frac{P(o_{t+1}^T, q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\\n           &= \\sum_{j=1}^N \\frac{P(o_{t+1}^T \\mathrel |q_t=S_i, q_{t+1}=S_j) \\cdot P(q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\\n           &= \\sum_{j=1}^N P(o_{t+1}^T \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\\n           &= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | o_{t+2}^T, q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\\n           &= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\\n           &= b_j(o_{t+1}) \\cdot \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot a_{ij} \\\\\n\\end{align}\n\n\n---\n\n### HMM - 参数训练 (Parameter Learning)\n\n对于观测序列 $O$, 求HMM参数 $\\lambda=(A, B, \\pi)$ 的最大似然估计:\n\n#### EM 算法\n\n##### E步\n\nEM算法的通用E步期望公式:\n\n\\begin{align}\nH(\\theta, P(Z\\mathrel | Y, \\hat{\\theta})) &= E_{Z\\sim P(Z\\mathrel | Y, \\hat{\\theta})} [\\log P(Y,Z \\mathrel | \\theta)] \\\\\n                        &= \\sum_Z P(Z\\mathrel | Y, \\hat{\\theta}) \\cdot \\log P(Y,Z \\mathrel | \\theta)\n\\end{align}\n\n代入HMM的参数:\n\n\\begin{align}\nH(\\lambda, P(O\\mathrel | Q, \\hat{\\lambda})) &= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log P(O,Q \\mathrel | \\lambda) \\\\\n                                            &= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (P(q_1)\\cdot P(o_1 \\mathrel | q_1)\\prod_{t=2}^T P(q_{t-1} \\mathrel | q_t) \\cdot P(o_1 \\mathrel | q_1)) \\\\\n                                            &= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1}\\cdot b_{q_1}(o_1)\\prod_{t=2}^T a_{q_{t-1}q_{t}} \\cdot b_{q_t}(o_t)) \\\\\n                                            &= (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1})) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=1}^T \\log b_{q_t}(o_t)) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=2}^T \\log a_{q_{t-1}q_{t}})\n\\end{align}\n \n##### M步\n\n\n\n","slug":"HMM","published":1,"updated":"2019-07-26T12:52:02.997Z","_id":"cjyiirp5c0006o8he7n29ep5m","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>本文记录了HMM模型的基本理论及其EM算法的优化</p>\n</blockquote>\n<h3 id=\"HMM-的组成\"><a href=\"#HMM-的组成\" class=\"headerlink\" title=\"HMM 的组成\"></a>HMM 的组成</h3><p><strong> HMM的参数: $ \\lambda = (A, B, \\pi) $</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>五元组</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>$S = {s_1, s_2, \\dots, s_N}$</td>\n<td>隐藏状态集合</td>\n</tr>\n<tr>\n<td>$V = {v_1, v_2, \\dots, v_m, \\dots}$</td>\n<td>观测值集合</td>\n</tr>\n<tr>\n<td>$A = a_{11}, \\dots, a_{ij}, \\dots, a_{NN}$</td>\n<td>转移概率矩阵, $\\sum_{j=1}^N a_{ij} = 1$</td>\n</tr>\n<tr>\n<td>$B = b_i(v_j)$</td>\n<td>发射概率: 隐藏状态 $s_i$ 产生观测值 $v_j$ 的概率</td>\n</tr>\n<tr>\n<td>$\\pi = \\pi_1, \\pi_2, \\dots, \\pi_n$</td>\n<td>起始概率: 隐藏状态 $s_i$成为第一个隐藏状态的概率，$\\sum_{i=1}^N \\pi_i = 1$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>其它符号</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>$q_{t_1}^{t_2}$</td>\n<td>从时间$t_1$到$t_2$的隐藏状态序列</td>\n</tr>\n<tr>\n<td>$Q = q_1q_2\\dots q_T$</td>\n<td>隐藏状态序列, $q_i \\in S$, $q_1^T$</td>\n</tr>\n<tr>\n<td>$o_{t_1}^{t_2}$</td>\n<td>从时间$t_1$到$t_2$的观测值序列</td>\n</tr>\n<tr>\n<td>$O = o_1o_2\\dots o_T$</td>\n<td>观测值序列, $o_i \\in V$, $o_1^T$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<h3 id=\"HMM-的基本假设\"><a href=\"#HMM-的基本假设\" class=\"headerlink\" title=\"HMM 的基本假设\"></a>HMM 的基本假设</h3><ol>\n<li><p>马尔科夫假设</p>\n<script type=\"math/tex; mode=display\">\nP(q_i \\mathrel | q_1\\dots q_{i-1}) = P(q_i\\mathrel | q_{i-1})</script></li>\n<li><p>观测值独立性假设</p>\n</li>\n</ol>\n<script type=\"math/tex; mode=display\">\nP(o_i \\mathrel | q_1\\dots q_i\\dots q_T, o_1\\dots o_i \\dots o_T) = P(o_i \\mathrel | q_i)</script><hr>\n<h3 id=\"HMM-似然-Likelihood\"><a href=\"#HMM-似然-Likelihood\" class=\"headerlink\" title=\"HMM - 似然 (Likelihood)\"></a>HMM - 似然 (Likelihood)</h3><p>对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求观测序列的似然 $P(O \\mathrel | \\lambda)$。  ( 以下省略 $\\lambda$ ) </p>\n<h4 id=\"前向算法-Forward-Algoithm\"><a href=\"#前向算法-Forward-Algoithm\" class=\"headerlink\" title=\"前向算法 (Forward Algoithm)\"></a>前向算法 (Forward Algoithm)</h4><p>令 $ \\alpha_t(i) = P(o_1^t, q_t=S_i)$ , 则似然观测概率的似然可以表示为: </p>\n<p>\\begin{align}<br>P(O)    &amp;= \\sum_{i=1}^N P(o_i^T, q_T=S_i) \\\\<br>        &amp;= \\sum_{i=1}^N \\alpha_T(i)<br>\\end{align}</p>\n<h5 id=\"前向递归式\"><a href=\"#前向递归式\" class=\"headerlink\" title=\"前向递归式\"></a>前向递归式</h5><p>\\begin{align}<br>\\alpha_t(i) &amp;=  P(o_1^t, q_t=S_i)\\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^t, q_{t-1}=S_j, q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N \\alpha_{t-1}(j) \\cdot a_{ji} \\cdot b_i(o_t)<br>\\end{align}</p>\n<p>其中，初值:<br>\\begin{align}<br>\\alpha_1(i) &amp;= P(o_1, q_1=S_i) \\\\<br>            &amp;= P(q_1=S_i) \\cdot P(o_1 \\mathrel | q_1=S_i) \\\\<br>            &amp;= \\pi_i \\cdot b_i(o_1)<br>\\end{align}</p>\n<hr>\n<h3 id=\"HMM-解码-Decoding\"><a href=\"#HMM-解码-Decoding\" class=\"headerlink\" title=\"HMM - 解码 (Decoding)\"></a>HMM - 解码 (Decoding)</h3><p>对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求最可能的状态序列 $Q$:<br>\\begin{align}<br>Q   &amp;= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(Q \\mathrel | Q) \\\\<br>    &amp;= \\underset{q_1^T}{\\mathrm{argmax}}\\ \\frac{P(q_1^T, o_1^T)}{P(o_1^T)} \\\\<br>    &amp;= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(q_1^T, o_1^T)<br>\\end{align}</p>\n<p>令:</p>\n<script type=\"math/tex; mode=display\">\n\\delta_i(t) = \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i)</script><p>则 $Q$ 的最后一个状态为:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nq_T &= \\underset{q_1^{T-1}}{\\mathrm{argmax}}\\ \\max_{i=1}^N P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{T-1}} P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(T)\n\\end{align}\\label{eq:viterbi-last-state}\\tag{1}</script><h4 id=\"Viterbi-算法\"><a href=\"#Viterbi-算法\" class=\"headerlink\" title=\"Viterbi 算法\"></a>Viterbi 算法</h4><h5 id=\"递归-Recursion\"><a href=\"#递归-Recursion\" class=\"headerlink\" title=\"递归 (Recursion)\"></a>递归 (Recursion)</h5><script type=\"math/tex; mode=display\">\n\\begin{align}\n\\delta_i(t) &= \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_1^{t-1}) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | q_{t-1}) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-2}} \\max_{j=1}^N P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\cdot \\max_{j=1}^N P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot \\max_{q_1^{t-2}} P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\max_{j=1}^N a_{ji} \\cdot \\delta_j(t-1)\n\\end{align}\\label{eq:viterbi-recursion}\\tag{2}</script><p>其中，初值:<br>\\begin{align}<br>\\delta_i(1) &amp;= P(o_1, q_1=S_i) \\\\<br>            &amp;= \\pi_i \\cdot b_i(o_1)  \\\\<br>            &amp;= \\alpha_1(i)<br>\\end{align}</p>\n<p>此时，将递归式 Eq.(\\ref{eq:viterbi-recursion}) 应用到 Eq.(\\ref{eq:viterbi-last-state}) 中可以得到最可能路径的最后一个状态。</p>\n<h5 id=\"回溯-Traceback\"><a href=\"#回溯-Traceback\" class=\"headerlink\" title=\"回溯 (Traceback)\"></a>回溯 (Traceback)</h5><p>已知最可能路径中的第 $t+1$ 个状态 $q_{t+1}^*$, 求该路径中的第 $t$ 个状态:</p>\n<p>\\begin{align}<br>q_t &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+2}^T, q_{t+1}^*, q_t=S_i, o_1^T) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^*) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\cdot \\max_{q_{t+2}^T} P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^*) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^* \\mathrel | q_1^{t-1}, q_t=S_i, o_1^t) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^* \\mathrel | q_{t-1}) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(t) \\cdot a_{iq_{t+1}^*}<br>\\end{align}</p>\n<hr>\n<h3 id=\"HMM-后验解码-Posterior-Decoding\"><a href=\"#HMM-后验解码-Posterior-Decoding\" class=\"headerlink\" title=\"HMM - 后验解码 (Posterior Decoding)\"></a>HMM - 后验解码 (Posterior Decoding)</h3><p>对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求时间$t$处的最可能状态:</p>\n<p>\\begin{align}<br>q_t &amp;= \\underset{i}{\\mathrm{argmax}}\\ P(q_t=S_i \\mathrel | O)  \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)}<br>\\end{align}</p>\n<p>令:</p>\n<script type=\"math/tex; mode=display\">\n\\beta_i(t) = P(o_{t+1}^T \\mathrel | q_t=S_i)</script><p>则 $t$ 时间处隐藏状态 $q_t$ 为 $S_i$ 的后验概率可表示为:<br>\\begin{align}<br>P(q_t=S_i \\mathrel |o_1^T)  &amp;= \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\<br>                            &amp;= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i, o_1^t)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)}  \\\\<br>                            &amp;= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\<br>                            &amp;= \\frac{\\alpha_i(t)\\cdot \\beta_i(t)}{\\sum_{k=1}^N \\alpha_i(k)\\cdot \\beta_i(k)} \\\\<br>\\end{align}</p>\n<h4 id=\"后向递归式\"><a href=\"#后向递归式\" class=\"headerlink\" title=\"后向递归式\"></a>后向递归式</h4><p>\\begin{align}<br>\\beta_i(t) &amp;= P(o_{t+1}^T \\mathrel | q_t=S_i) \\\\<br>           &amp;= \\sum_{j=1}^N \\frac{P(o_{t+1}^T, q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\<br>           &amp;= \\sum_{j=1}^N \\frac{P(o_{t+1}^T \\mathrel |q_t=S_i, q_{t+1}=S_j) \\cdot P(q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\<br>           &amp;= \\sum_{j=1}^N P(o_{t+1}^T \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\<br>           &amp;= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | o_{t+2}^T, q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\<br>           &amp;= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\<br>           &amp;= b_j(o_{t+1}) \\cdot \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot a_{ij} \\\\<br>\\end{align}</p>\n<hr>\n<h3 id=\"HMM-参数训练-Parameter-Learning\"><a href=\"#HMM-参数训练-Parameter-Learning\" class=\"headerlink\" title=\"HMM - 参数训练 (Parameter Learning)\"></a>HMM - 参数训练 (Parameter Learning)</h3><p>对于观测序列 $O$, 求HMM参数 $\\lambda=(A, B, \\pi)$ 的最大似然估计:</p>\n<h4 id=\"EM-算法\"><a href=\"#EM-算法\" class=\"headerlink\" title=\"EM 算法\"></a>EM 算法</h4><h5 id=\"E步\"><a href=\"#E步\" class=\"headerlink\" title=\"E步\"></a>E步</h5><p>EM算法的通用E步期望公式:</p>\n<p>\\begin{align}<br>H(\\theta, P(Z\\mathrel | Y, \\hat{\\theta})) &amp;= E_{Z\\sim P(Z\\mathrel | Y, \\hat{\\theta})} [\\log P(Y,Z \\mathrel | \\theta)] \\\\<br>                        &amp;= \\sum_Z P(Z\\mathrel | Y, \\hat{\\theta}) \\cdot \\log P(Y,Z \\mathrel | \\theta)<br>\\end{align}</p>\n<p>代入HMM的参数:</p>\n<p>\\begin{align}<br>H(\\lambda, P(O\\mathrel | Q, \\hat{\\lambda})) &amp;= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log P(O,Q \\mathrel | \\lambda) \\\\<br>                                            &amp;= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (P(q_1)\\cdot P(o_1 \\mathrel | q_1)\\prod_{t=2}^T P(q_{t-1} \\mathrel | q_t) \\cdot P(o_1 \\mathrel | q_1)) \\\\<br>                                            &amp;= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1}\\cdot b_{q_1}(o_1)\\prod_{t=2}^T a_{q_{t-1}q_{t}} \\cdot b_{q_t}(o_t)) \\\\<br>                                            &amp;= (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1})) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=1}^T \\log b_{q_t}(o_t)) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=2}^T \\log a_{q_{t-1}q_{t}})<br>\\end{align}</p>\n<h5 id=\"M步\"><a href=\"#M步\" class=\"headerlink\" title=\"M步\"></a>M步</h5>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文记录了HMM模型的基本理论及其EM算法的优化</p>\n</blockquote>\n<h3 id=\"HMM-的组成\"><a href=\"#HMM-的组成\" class=\"headerlink\" title=\"HMM 的组成\"></a>HMM 的组成</h3><p><strong> HMM的参数: $ \\lambda = (A, B, \\pi) $</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>五元组</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>$S = {s_1, s_2, \\dots, s_N}$</td>\n<td>隐藏状态集合</td>\n</tr>\n<tr>\n<td>$V = {v_1, v_2, \\dots, v_m, \\dots}$</td>\n<td>观测值集合</td>\n</tr>\n<tr>\n<td>$A = a_{11}, \\dots, a_{ij}, \\dots, a_{NN}$</td>\n<td>转移概率矩阵, $\\sum_{j=1}^N a_{ij} = 1$</td>\n</tr>\n<tr>\n<td>$B = b_i(v_j)$</td>\n<td>发射概率: 隐藏状态 $s_i$ 产生观测值 $v_j$ 的概率</td>\n</tr>\n<tr>\n<td>$\\pi = \\pi_1, \\pi_2, \\dots, \\pi_n$</td>\n<td>起始概率: 隐藏状态 $s_i$成为第一个隐藏状态的概率，$\\sum_{i=1}^N \\pi_i = 1$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>其它符号</th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>$q_{t_1}^{t_2}$</td>\n<td>从时间$t_1$到$t_2$的隐藏状态序列</td>\n</tr>\n<tr>\n<td>$Q = q_1q_2\\dots q_T$</td>\n<td>隐藏状态序列, $q_i \\in S$, $q_1^T$</td>\n</tr>\n<tr>\n<td>$o_{t_1}^{t_2}$</td>\n<td>从时间$t_1$到$t_2$的观测值序列</td>\n</tr>\n<tr>\n<td>$O = o_1o_2\\dots o_T$</td>\n<td>观测值序列, $o_i \\in V$, $o_1^T$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<h3 id=\"HMM-的基本假设\"><a href=\"#HMM-的基本假设\" class=\"headerlink\" title=\"HMM 的基本假设\"></a>HMM 的基本假设</h3><ol>\n<li><p>马尔科夫假设</p>\n<script type=\"math/tex; mode=display\">\nP(q_i \\mathrel | q_1\\dots q_{i-1}) = P(q_i\\mathrel | q_{i-1})</script></li>\n<li><p>观测值独立性假设</p>\n</li>\n</ol>\n<script type=\"math/tex; mode=display\">\nP(o_i \\mathrel | q_1\\dots q_i\\dots q_T, o_1\\dots o_i \\dots o_T) = P(o_i \\mathrel | q_i)</script><hr>\n<h3 id=\"HMM-似然-Likelihood\"><a href=\"#HMM-似然-Likelihood\" class=\"headerlink\" title=\"HMM - 似然 (Likelihood)\"></a>HMM - 似然 (Likelihood)</h3><p>对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求观测序列的似然 $P(O \\mathrel | \\lambda)$。  ( 以下省略 $\\lambda$ ) </p>\n<h4 id=\"前向算法-Forward-Algoithm\"><a href=\"#前向算法-Forward-Algoithm\" class=\"headerlink\" title=\"前向算法 (Forward Algoithm)\"></a>前向算法 (Forward Algoithm)</h4><p>令 $ \\alpha_t(i) = P(o_1^t, q_t=S_i)$ , 则似然观测概率的似然可以表示为: </p>\n<p>\\begin{align}<br>P(O)    &amp;= \\sum_{i=1}^N P(o_i^T, q_T=S_i) \\\\<br>        &amp;= \\sum_{i=1}^N \\alpha_T(i)<br>\\end{align}</p>\n<h5 id=\"前向递归式\"><a href=\"#前向递归式\" class=\"headerlink\" title=\"前向递归式\"></a>前向递归式</h5><p>\\begin{align}<br>\\alpha_t(i) &amp;=  P(o_1^t, q_t=S_i)\\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^t, q_{t-1}=S_j, q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j, q_t=S_i) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N P(o_1^{t-1}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\<br>            &amp;=  \\sum_{j=1}^N \\alpha_{t-1}(j) \\cdot a_{ji} \\cdot b_i(o_t)<br>\\end{align}</p>\n<p>其中，初值:<br>\\begin{align}<br>\\alpha_1(i) &amp;= P(o_1, q_1=S_i) \\\\<br>            &amp;= P(q_1=S_i) \\cdot P(o_1 \\mathrel | q_1=S_i) \\\\<br>            &amp;= \\pi_i \\cdot b_i(o_1)<br>\\end{align}</p>\n<hr>\n<h3 id=\"HMM-解码-Decoding\"><a href=\"#HMM-解码-Decoding\" class=\"headerlink\" title=\"HMM - 解码 (Decoding)\"></a>HMM - 解码 (Decoding)</h3><p>对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求最可能的状态序列 $Q$:<br>\\begin{align}<br>Q   &amp;= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(Q \\mathrel | Q) \\\\<br>    &amp;= \\underset{q_1^T}{\\mathrm{argmax}}\\ \\frac{P(q_1^T, o_1^T)}{P(o_1^T)} \\\\<br>    &amp;= \\underset{q_1^T}{\\mathrm{argmax}}\\ P(q_1^T, o_1^T)<br>\\end{align}</p>\n<p>令:</p>\n<script type=\"math/tex; mode=display\">\n\\delta_i(t) = \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i)</script><p>则 $Q$ 的最后一个状态为:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nq_T &= \\underset{q_1^{T-1}}{\\mathrm{argmax}}\\ \\max_{i=1}^N P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{T-1}} P(q_1^{T-1}, o_1^T, q_T=S_i) \\\\\n    &= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(T)\n\\end{align}\\label{eq:viterbi-last-state}\\tag{1}</script><h4 id=\"Viterbi-算法\"><a href=\"#Viterbi-算法\" class=\"headerlink\" title=\"Viterbi 算法\"></a>Viterbi 算法</h4><h5 id=\"递归-Recursion\"><a href=\"#递归-Recursion\" class=\"headerlink\" title=\"递归 (Recursion)\"></a>递归 (Recursion)</h5><script type=\"math/tex; mode=display\">\n\\begin{align}\n\\delta_i(t) &= \\max_{q_1^{t-1}} P(o_1^t, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\cdot P(o_t \\mathrel | o_1^{t-1}, q_1^{t-1}, q_t=S_i) \\\\\n            &= \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | o_1^{t-1}, q_1^{t-1}) \\cdot P(o_t \\mathrel | q_t=S_i) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-1}} P(o_1^{t-1}, q_1^{t-1}) \\cdot P(q_t=S_i \\mathrel | q_{t-1}) \\\\\n            &= b_i(o_t) \\cdot \\max_{q_1^{t-2}} \\max_{j=1}^N P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\cdot P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\cdot \\max_{j=1}^N P(q_t=S_i \\mathrel | q_{t-1}=S_j) \\cdot \\max_{q_1^{t-2}} P(o_1^{t-1}, q_1^{t-2}, q_{t-1}=S_j) \\\\\n            &= b_i(o_t) \\max_{j=1}^N a_{ji} \\cdot \\delta_j(t-1)\n\\end{align}\\label{eq:viterbi-recursion}\\tag{2}</script><p>其中，初值:<br>\\begin{align}<br>\\delta_i(1) &amp;= P(o_1, q_1=S_i) \\\\<br>            &amp;= \\pi_i \\cdot b_i(o_1)  \\\\<br>            &amp;= \\alpha_1(i)<br>\\end{align}</p>\n<p>此时，将递归式 Eq.(\\ref{eq:viterbi-recursion}) 应用到 Eq.(\\ref{eq:viterbi-last-state}) 中可以得到最可能路径的最后一个状态。</p>\n<h5 id=\"回溯-Traceback\"><a href=\"#回溯-Traceback\" class=\"headerlink\" title=\"回溯 (Traceback)\"></a>回溯 (Traceback)</h5><p>已知最可能路径中的第 $t+1$ 个状态 $q_{t+1}^*$, 求该路径中的第 $t$ 个状态:</p>\n<p>\\begin{align}<br>q_t &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+2}^T, q_{t+1}^*, q_t=S_i, o_1^T) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}, q_{t+2}^T} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^*) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\cdot \\max_{q_{t+2}^T} P(o_{t+1}^T, q_{t+2}^T \\mathrel | q_{t+1}^*) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_{t+1}^*, q_t=S_i, o_1^t) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^* \\mathrel | q_1^{t-1}, q_t=S_i, o_1^t) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\max_{q_1^{t-1}} P(q_1^{t-1}, q_t=S_i, o_1^t) \\cdot P(q_{t+1}^* \\mathrel | q_{t-1}) \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\delta_i(t) \\cdot a_{iq_{t+1}^*}<br>\\end{align}</p>\n<hr>\n<h3 id=\"HMM-后验解码-Posterior-Decoding\"><a href=\"#HMM-后验解码-Posterior-Decoding\" class=\"headerlink\" title=\"HMM - 后验解码 (Posterior Decoding)\"></a>HMM - 后验解码 (Posterior Decoding)</h3><p>对于HMM $\\lambda = (A, B, \\pi)$ 和观测序列 $O$, 求时间$t$处的最可能状态:</p>\n<p>\\begin{align}<br>q_t &amp;= \\underset{i}{\\mathrm{argmax}}\\ P(q_t=S_i \\mathrel | O)  \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{P(o_1^T)}  \\\\<br>    &amp;= \\underset{i}{\\mathrm{argmax}}\\ \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)}<br>\\end{align}</p>\n<p>令:</p>\n<script type=\"math/tex; mode=display\">\n\\beta_i(t) = P(o_{t+1}^T \\mathrel | q_t=S_i)</script><p>则 $t$ 时间处隐藏状态 $q_t$ 为 $S_i$ 的后验概率可表示为:<br>\\begin{align}<br>P(q_t=S_i \\mathrel |o_1^T)  &amp;= \\frac{P(q_t=S_i, o_1^T)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\<br>                            &amp;= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i, o_1^t)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)}  \\\\<br>                            &amp;= \\frac{P(q_t=S_i, o_1^t) \\cdot P(o_{t+1}^T \\mathrel | q_t=S_i)}{\\sum_{k=1}^N P(q_t=S_k, o_1^T)} \\\\<br>                            &amp;= \\frac{\\alpha_i(t)\\cdot \\beta_i(t)}{\\sum_{k=1}^N \\alpha_i(k)\\cdot \\beta_i(k)} \\\\<br>\\end{align}</p>\n<h4 id=\"后向递归式\"><a href=\"#后向递归式\" class=\"headerlink\" title=\"后向递归式\"></a>后向递归式</h4><p>\\begin{align}<br>\\beta_i(t) &amp;= P(o_{t+1}^T \\mathrel | q_t=S_i) \\\\<br>           &amp;= \\sum_{j=1}^N \\frac{P(o_{t+1}^T, q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\<br>           &amp;= \\sum_{j=1}^N \\frac{P(o_{t+1}^T \\mathrel |q_t=S_i, q_{t+1}=S_j) \\cdot P(q_t=S_i, q_{t+1}=S_j)}{P(q_t=S_i)} \\\\<br>           &amp;= \\sum_{j=1}^N P(o_{t+1}^T \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\<br>           &amp;= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | o_{t+2}^T, q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\<br>           &amp;= \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot P(o_{t+1} \\mathrel | q_{t+1}=S_j) \\cdot P(q_{t+1}=S_j \\mathrel | q_{t}=S_i) \\\\<br>           &amp;= b_j(o_{t+1}) \\cdot \\sum_{j=1}^N P(o_{t+2}^T \\mathrel | q_{t+1}=S_j) \\cdot a_{ij} \\\\<br>\\end{align}</p>\n<hr>\n<h3 id=\"HMM-参数训练-Parameter-Learning\"><a href=\"#HMM-参数训练-Parameter-Learning\" class=\"headerlink\" title=\"HMM - 参数训练 (Parameter Learning)\"></a>HMM - 参数训练 (Parameter Learning)</h3><p>对于观测序列 $O$, 求HMM参数 $\\lambda=(A, B, \\pi)$ 的最大似然估计:</p>\n<h4 id=\"EM-算法\"><a href=\"#EM-算法\" class=\"headerlink\" title=\"EM 算法\"></a>EM 算法</h4><h5 id=\"E步\"><a href=\"#E步\" class=\"headerlink\" title=\"E步\"></a>E步</h5><p>EM算法的通用E步期望公式:</p>\n<p>\\begin{align}<br>H(\\theta, P(Z\\mathrel | Y, \\hat{\\theta})) &amp;= E_{Z\\sim P(Z\\mathrel | Y, \\hat{\\theta})} [\\log P(Y,Z \\mathrel | \\theta)] \\\\<br>                        &amp;= \\sum_Z P(Z\\mathrel | Y, \\hat{\\theta}) \\cdot \\log P(Y,Z \\mathrel | \\theta)<br>\\end{align}</p>\n<p>代入HMM的参数:</p>\n<p>\\begin{align}<br>H(\\lambda, P(O\\mathrel | Q, \\hat{\\lambda})) &amp;= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log P(O,Q \\mathrel | \\lambda) \\\\<br>                                            &amp;= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (P(q_1)\\cdot P(o_1 \\mathrel | q_1)\\prod_{t=2}^T P(q_{t-1} \\mathrel | q_t) \\cdot P(o_1 \\mathrel | q_1)) \\\\<br>                                            &amp;= \\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1}\\cdot b_{q_1}(o_1)\\prod_{t=2}^T a_{q_{t-1}q_{t}} \\cdot b_{q_t}(o_t)) \\\\<br>                                            &amp;= (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\log (\\pi_{q_1})) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=1}^T \\log b_{q_t}(o_t)) + (\\sum_Q P(O\\mathrel | Q, \\hat{\\lambda}) \\cdot \\sum_{t=2}^T \\log a_{q_{t-1}q_{t}})<br>\\end{align}</p>\n<h5 id=\"M步\"><a href=\"#M步\" class=\"headerlink\" title=\"M步\"></a>M步</h5>"},{"title":"[Hexo] Theme HuWeihuang","catalog":true,"toc_nav_num":true,"date":"2017-09-18T02:51:24.000Z","subtitle":"This is hexo theme Demo.","header-img":"/img/article_header/article_header.png","top":0,"catagories":["Hexo"],"_content":"> This HuWeihuang theme created by [HuWeihuang](http://www.huweihuang.com/) modified from the original Porter [YuHsuan](https://github.com/YenYuHsuan/hexo-theme-beantech)\n\n# Live Demo\n\nHu Weihuang Blog : [www.huweihuang.com](http://www.huweihuang.com/)\n\n![Theme HuWeihuang](http://img.huweihuang.com/blog.jpg)\n\n# Install Hexo\n\nInstall Node.js  and Git\n\n```shell\n#For Mac\nbrew install node\nbrew install git\n```\n\nInstall hexo\n\n```shell\nnpm install hexo-cli -g\n\n#For more:https://hexo.io/zh-cn/index.html\n```\n\n# Theme Usage\n\n## Init\n\n---\n```bash\ngit clone https://github.com/huweihuang/hexo-theme-huweihuang.git ./hexo-huweihuang\ncd hexo-huweihuang\nnpm install\n```\n\n## Modify\n---\nModify `_config.yml` file with your own info.\nEspecially the section:\n### Deployment\nReplace to your own repo!\n```yml\ndeploy:\n  type: git\n  repo: https://github.com/<yourAccount>/<repo>\n  branch: <your-branch>\n```\n\n### Sidebar settings\nCopy your avatar image to `<root>/img/` and modify the `_config.yml`:\n```yml\nsidebar: true    # whether or not using Sidebar.\nsidebar-about-description: \"<your description>\"\nsidebar-avatar: img/<your avatar path>\n```\nand activate your personal widget you like\n```yml\nwidgets:         # here are widget you can use, you can comment out\n- featured-tags\n- short-about\n- recent-posts\n- friends-blog\n- archive\n- category\n```\nif you want to add sidebar widget, please add at `layout/_widget`.\n### Signature Setup\nCopy your signature image to `<root>/img/signature` and modify the `_config.yml`:\n```yml\nsignature: true   # show signature\nsignature-img: img/signature/<your-signature-ID>\n```\n### Go to top icon Setup\nMy icon is using iron man, you can change to your own icon at `css/image`.\n\n### Post tag\nYou can decide to show post tags or not.\n```yml\nhome_posts_tag: true\n```\n![home_posts_tag-true](/img/article/tag.png)\n### Markdown render\nMy markdown render engine plugin is [hexo-renderer-markdown-it](https://github.com/celsomiranda/hexo-renderer-markdown-it).\n```yml\n# Markdown-it config\n## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki\nmarkdown:\n  render:\n    html: true\n    xhtmlOut: false\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n```\nand if you want to change the header anchor 'ℬ', you can go to `layout/post.ejs` to change it.\n```javascript\nasync(\"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\",function(){\n        anchors.options = {\n          visible: 'hover',\n          placement: 'left',\n          icon: ℬ // this is the header anchor \"unicode\" icon\n        };\n```\n\n## Hexo Basics\n---\nSome hexo command:\n```bash\nhexo new post \"<post name>\" # you can change post to another layout if you want\nhexo clean && hexo generate # generate the static file\nhexo server # run hexo in local environment\nhexo deploy # hexo will push the static files automatically into the specific branch(gh-pages) of your repo!\n```\n\n# Have fun ^_^ \n---\n<!-- Place this tag in your head or just before your close body tag. -->\n<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n<!-- Place this tag where you want the button to render. -->\n\nPlease <a class=\"github-button\" href=\"https://github.com/huweihuang/hexo-theme-huweihuang\" data-icon=\"octicon-star\" aria-label=\"Star huweihuang/hexo-theme-huweihuang on GitHub\">Star</a> this Project if you like it! <a class=\"github-button\" href=\"https://github.com/huweihuang\" aria-label=\"Follow @huweihuang on GitHub\">Follow</a> would also be appreciated!\nPeace!\n","source":"_posts/hexo-theme-huweihuang.md","raw":"---\ntitle: \"[Hexo] Theme HuWeihuang\"\ncatalog: true\ntoc_nav_num: true\ndate: 2017-09-18 10:51:24\nsubtitle: \"This is hexo theme Demo.\"\nheader-img: \"/img/article_header/article_header.png\"\ntop: 0\ntags:\n- Hexo\ncatagories:\n- Hexo\n\n---\n> This HuWeihuang theme created by [HuWeihuang](http://www.huweihuang.com/) modified from the original Porter [YuHsuan](https://github.com/YenYuHsuan/hexo-theme-beantech)\n\n# Live Demo\n\nHu Weihuang Blog : [www.huweihuang.com](http://www.huweihuang.com/)\n\n![Theme HuWeihuang](http://img.huweihuang.com/blog.jpg)\n\n# Install Hexo\n\nInstall Node.js  and Git\n\n```shell\n#For Mac\nbrew install node\nbrew install git\n```\n\nInstall hexo\n\n```shell\nnpm install hexo-cli -g\n\n#For more:https://hexo.io/zh-cn/index.html\n```\n\n# Theme Usage\n\n## Init\n\n---\n```bash\ngit clone https://github.com/huweihuang/hexo-theme-huweihuang.git ./hexo-huweihuang\ncd hexo-huweihuang\nnpm install\n```\n\n## Modify\n---\nModify `_config.yml` file with your own info.\nEspecially the section:\n### Deployment\nReplace to your own repo!\n```yml\ndeploy:\n  type: git\n  repo: https://github.com/<yourAccount>/<repo>\n  branch: <your-branch>\n```\n\n### Sidebar settings\nCopy your avatar image to `<root>/img/` and modify the `_config.yml`:\n```yml\nsidebar: true    # whether or not using Sidebar.\nsidebar-about-description: \"<your description>\"\nsidebar-avatar: img/<your avatar path>\n```\nand activate your personal widget you like\n```yml\nwidgets:         # here are widget you can use, you can comment out\n- featured-tags\n- short-about\n- recent-posts\n- friends-blog\n- archive\n- category\n```\nif you want to add sidebar widget, please add at `layout/_widget`.\n### Signature Setup\nCopy your signature image to `<root>/img/signature` and modify the `_config.yml`:\n```yml\nsignature: true   # show signature\nsignature-img: img/signature/<your-signature-ID>\n```\n### Go to top icon Setup\nMy icon is using iron man, you can change to your own icon at `css/image`.\n\n### Post tag\nYou can decide to show post tags or not.\n```yml\nhome_posts_tag: true\n```\n![home_posts_tag-true](/img/article/tag.png)\n### Markdown render\nMy markdown render engine plugin is [hexo-renderer-markdown-it](https://github.com/celsomiranda/hexo-renderer-markdown-it).\n```yml\n# Markdown-it config\n## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki\nmarkdown:\n  render:\n    html: true\n    xhtmlOut: false\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n```\nand if you want to change the header anchor 'ℬ', you can go to `layout/post.ejs` to change it.\n```javascript\nasync(\"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\",function(){\n        anchors.options = {\n          visible: 'hover',\n          placement: 'left',\n          icon: ℬ // this is the header anchor \"unicode\" icon\n        };\n```\n\n## Hexo Basics\n---\nSome hexo command:\n```bash\nhexo new post \"<post name>\" # you can change post to another layout if you want\nhexo clean && hexo generate # generate the static file\nhexo server # run hexo in local environment\nhexo deploy # hexo will push the static files automatically into the specific branch(gh-pages) of your repo!\n```\n\n# Have fun ^_^ \n---\n<!-- Place this tag in your head or just before your close body tag. -->\n<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n<!-- Place this tag where you want the button to render. -->\n\nPlease <a class=\"github-button\" href=\"https://github.com/huweihuang/hexo-theme-huweihuang\" data-icon=\"octicon-star\" aria-label=\"Star huweihuang/hexo-theme-huweihuang on GitHub\">Star</a> this Project if you like it! <a class=\"github-button\" href=\"https://github.com/huweihuang\" aria-label=\"Follow @huweihuang on GitHub\">Follow</a> would also be appreciated!\nPeace!\n","slug":"hexo-theme-huweihuang","published":1,"updated":"2019-07-22T06:53:48.599Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyiirp5e0008o8hem4e599my","content":"<blockquote>\n<p>This HuWeihuang theme created by <a href=\"http://www.huweihuang.com/\" target=\"_blank\" rel=\"noopener\">HuWeihuang</a> modified from the original Porter <a href=\"https://github.com/YenYuHsuan/hexo-theme-beantech\" target=\"_blank\" rel=\"noopener\">YuHsuan</a></p>\n</blockquote>\n<h1 id=\"Live-Demo\"><a href=\"#Live-Demo\" class=\"headerlink\" title=\"Live Demo\"></a>Live Demo</h1><p>Hu Weihuang Blog : <a href=\"http://www.huweihuang.com/\" target=\"_blank\" rel=\"noopener\">www.huweihuang.com</a></p>\n<p><img src=\"http://img.huweihuang.com/blog.jpg\" alt=\"Theme HuWeihuang\"></p>\n<h1 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h1><p>Install Node.js  and Git</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>For Mac</span><br><span class=\"line\">brew install node</span><br><span class=\"line\">brew install git</span><br></pre></td></tr></table></figure>\n<p>Install hexo</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-cli -g</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>For more:https://hexo.io/zh-cn/index.html</span><br></pre></td></tr></table></figure>\n<h1 id=\"Theme-Usage\"><a href=\"#Theme-Usage\" class=\"headerlink\" title=\"Theme Usage\"></a>Theme Usage</h1><h2 id=\"Init\"><a href=\"#Init\" class=\"headerlink\" title=\"Init\"></a>Init</h2><hr>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/huweihuang/hexo-theme-huweihuang.git ./hexo-huweihuang</span><br><span class=\"line\"><span class=\"built_in\">cd</span> hexo-huweihuang</span><br><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n<h2 id=\"Modify\"><a href=\"#Modify\" class=\"headerlink\" title=\"Modify\"></a>Modify</h2><hr>\n<p>Modify <code>_config.yml</code> file with your own info.<br>Especially the section:</p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>Replace to your own repo!<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repo:</span> <span class=\"attr\">https://github.com/&lt;yourAccount&gt;/&lt;repo&gt;</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">&lt;your-branch&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Sidebar-settings\"><a href=\"#Sidebar-settings\" class=\"headerlink\" title=\"Sidebar settings\"></a>Sidebar settings</h3><p>Copy your avatar image to <code>&lt;root&gt;/img/</code> and modify the <code>_config.yml</code>:<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">sidebar:</span> <span class=\"literal\">true</span>    <span class=\"comment\"># whether or not using Sidebar.</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-about-description:</span> <span class=\"string\">\"&lt;your description&gt;\"</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-avatar:</span> <span class=\"string\">img/&lt;your</span> <span class=\"string\">avatar</span> <span class=\"string\">path&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>and activate your personal widget you like<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">widgets:</span>         <span class=\"comment\"># here are widget you can use, you can comment out</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">featured-tags</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">short-about</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">recent-posts</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">friends-blog</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">archive</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">category</span></span><br></pre></td></tr></table></figure></p>\n<p>if you want to add sidebar widget, please add at <code>layout/_widget</code>.</p>\n<h3 id=\"Signature-Setup\"><a href=\"#Signature-Setup\" class=\"headerlink\" title=\"Signature Setup\"></a>Signature Setup</h3><p>Copy your signature image to <code>&lt;root&gt;/img/signature</code> and modify the <code>_config.yml</code>:<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">signature:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># show signature</span></span><br><span class=\"line\"><span class=\"attr\">signature-img:</span> <span class=\"string\">img/signature/&lt;your-signature-ID&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Go-to-top-icon-Setup\"><a href=\"#Go-to-top-icon-Setup\" class=\"headerlink\" title=\"Go to top icon Setup\"></a>Go to top icon Setup</h3><p>My icon is using iron man, you can change to your own icon at <code>css/image</code>.</p>\n<h3 id=\"Post-tag\"><a href=\"#Post-tag\" class=\"headerlink\" title=\"Post tag\"></a>Post tag</h3><p>You can decide to show post tags or not.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">home_posts_tag:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/img/article/tag.png\" alt=\"home_posts_tag-true\"></p>\n<h3 id=\"Markdown-render\"><a href=\"#Markdown-render\" class=\"headerlink\" title=\"Markdown render\"></a>Markdown render</h3><p>My markdown render engine plugin is <a href=\"https://github.com/celsomiranda/hexo-renderer-markdown-it\" target=\"_blank\" rel=\"noopener\">hexo-renderer-markdown-it</a>.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Markdown-it config</span></span><br><span class=\"line\"><span class=\"comment\">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class=\"line\"><span class=\"attr\">markdown:</span></span><br><span class=\"line\"><span class=\"attr\">  render:</span></span><br><span class=\"line\"><span class=\"attr\">    html:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    xhtmlOut:</span> <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"attr\">    breaks:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    linkify:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    typographer:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    quotes:</span> <span class=\"string\">'“”‘’'</span></span><br></pre></td></tr></table></figure></p>\n<p>and if you want to change the header anchor ‘ℬ’, you can go to <code>layout/post.ejs</code> to change it.<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">async</span>(<span class=\"string\">\"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\"</span>,<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">        anchors.options = &#123;</span><br><span class=\"line\">          visible: <span class=\"string\">'hover'</span>,</span><br><span class=\"line\">          placement: <span class=\"string\">'left'</span>,</span><br><span class=\"line\">          icon: ℬ <span class=\"comment\">// this is the header anchor \"unicode\" icon</span></span><br><span class=\"line\">        &#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Hexo-Basics\"><a href=\"#Hexo-Basics\" class=\"headerlink\" title=\"Hexo Basics\"></a>Hexo Basics</h2><hr>\n<p>Some hexo command:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new post <span class=\"string\">\"&lt;post name&gt;\"</span> <span class=\"comment\"># you can change post to another layout if you want</span></span><br><span class=\"line\">hexo clean &amp;&amp; hexo generate <span class=\"comment\"># generate the static file</span></span><br><span class=\"line\">hexo server <span class=\"comment\"># run hexo in local environment</span></span><br><span class=\"line\">hexo deploy <span class=\"comment\"># hexo will push the static files automatically into the specific branch(gh-pages) of your repo!</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Have-fun\"><a href=\"#Have-fun\" class=\"headerlink\" title=\"Have fun ^_^\"></a>Have fun ^_^</h1><hr>\n<!-- Place this tag in your head or just before your close body tag. -->\n<p><script async defer src=\"https://buttons.github.io/buttons.js\"></script><br><!-- Place this tag where you want the button to render. --></p>\n<p>Please <a class=\"github-button\" href=\"https://github.com/huweihuang/hexo-theme-huweihuang\" data-icon=\"octicon-star\" aria-label=\"Star huweihuang/hexo-theme-huweihuang on GitHub\" target=\"_blank\" rel=\"noopener\">Star</a> this Project if you like it! <a class=\"github-button\" href=\"https://github.com/huweihuang\" aria-label=\"Follow @huweihuang on GitHub\" target=\"_blank\" rel=\"noopener\">Follow</a> would also be appreciated!<br>Peace!</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>This HuWeihuang theme created by <a href=\"http://www.huweihuang.com/\" target=\"_blank\" rel=\"noopener\">HuWeihuang</a> modified from the original Porter <a href=\"https://github.com/YenYuHsuan/hexo-theme-beantech\" target=\"_blank\" rel=\"noopener\">YuHsuan</a></p>\n</blockquote>\n<h1 id=\"Live-Demo\"><a href=\"#Live-Demo\" class=\"headerlink\" title=\"Live Demo\"></a>Live Demo</h1><p>Hu Weihuang Blog : <a href=\"http://www.huweihuang.com/\" target=\"_blank\" rel=\"noopener\">www.huweihuang.com</a></p>\n<p><img src=\"http://img.huweihuang.com/blog.jpg\" alt=\"Theme HuWeihuang\"></p>\n<h1 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h1><p>Install Node.js  and Git</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>For Mac</span><br><span class=\"line\">brew install node</span><br><span class=\"line\">brew install git</span><br></pre></td></tr></table></figure>\n<p>Install hexo</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-cli -g</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>For more:https://hexo.io/zh-cn/index.html</span><br></pre></td></tr></table></figure>\n<h1 id=\"Theme-Usage\"><a href=\"#Theme-Usage\" class=\"headerlink\" title=\"Theme Usage\"></a>Theme Usage</h1><h2 id=\"Init\"><a href=\"#Init\" class=\"headerlink\" title=\"Init\"></a>Init</h2><hr>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/huweihuang/hexo-theme-huweihuang.git ./hexo-huweihuang</span><br><span class=\"line\"><span class=\"built_in\">cd</span> hexo-huweihuang</span><br><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n<h2 id=\"Modify\"><a href=\"#Modify\" class=\"headerlink\" title=\"Modify\"></a>Modify</h2><hr>\n<p>Modify <code>_config.yml</code> file with your own info.<br>Especially the section:</p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>Replace to your own repo!<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repo:</span> <span class=\"attr\">https://github.com/&lt;yourAccount&gt;/&lt;repo&gt;</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">&lt;your-branch&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Sidebar-settings\"><a href=\"#Sidebar-settings\" class=\"headerlink\" title=\"Sidebar settings\"></a>Sidebar settings</h3><p>Copy your avatar image to <code>&lt;root&gt;/img/</code> and modify the <code>_config.yml</code>:<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">sidebar:</span> <span class=\"literal\">true</span>    <span class=\"comment\"># whether or not using Sidebar.</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-about-description:</span> <span class=\"string\">\"&lt;your description&gt;\"</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-avatar:</span> <span class=\"string\">img/&lt;your</span> <span class=\"string\">avatar</span> <span class=\"string\">path&gt;</span></span><br></pre></td></tr></table></figure></p>\n<p>and activate your personal widget you like<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">widgets:</span>         <span class=\"comment\"># here are widget you can use, you can comment out</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">featured-tags</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">short-about</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">recent-posts</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">friends-blog</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">archive</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">category</span></span><br></pre></td></tr></table></figure></p>\n<p>if you want to add sidebar widget, please add at <code>layout/_widget</code>.</p>\n<h3 id=\"Signature-Setup\"><a href=\"#Signature-Setup\" class=\"headerlink\" title=\"Signature Setup\"></a>Signature Setup</h3><p>Copy your signature image to <code>&lt;root&gt;/img/signature</code> and modify the <code>_config.yml</code>:<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">signature:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># show signature</span></span><br><span class=\"line\"><span class=\"attr\">signature-img:</span> <span class=\"string\">img/signature/&lt;your-signature-ID&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Go-to-top-icon-Setup\"><a href=\"#Go-to-top-icon-Setup\" class=\"headerlink\" title=\"Go to top icon Setup\"></a>Go to top icon Setup</h3><p>My icon is using iron man, you can change to your own icon at <code>css/image</code>.</p>\n<h3 id=\"Post-tag\"><a href=\"#Post-tag\" class=\"headerlink\" title=\"Post tag\"></a>Post tag</h3><p>You can decide to show post tags or not.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">home_posts_tag:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/img/article/tag.png\" alt=\"home_posts_tag-true\"></p>\n<h3 id=\"Markdown-render\"><a href=\"#Markdown-render\" class=\"headerlink\" title=\"Markdown render\"></a>Markdown render</h3><p>My markdown render engine plugin is <a href=\"https://github.com/celsomiranda/hexo-renderer-markdown-it\" target=\"_blank\" rel=\"noopener\">hexo-renderer-markdown-it</a>.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Markdown-it config</span></span><br><span class=\"line\"><span class=\"comment\">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class=\"line\"><span class=\"attr\">markdown:</span></span><br><span class=\"line\"><span class=\"attr\">  render:</span></span><br><span class=\"line\"><span class=\"attr\">    html:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    xhtmlOut:</span> <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"attr\">    breaks:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    linkify:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    typographer:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">    quotes:</span> <span class=\"string\">'“”‘’'</span></span><br></pre></td></tr></table></figure></p>\n<p>and if you want to change the header anchor ‘ℬ’, you can go to <code>layout/post.ejs</code> to change it.<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">async</span>(<span class=\"string\">\"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\"</span>,<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">        anchors.options = &#123;</span><br><span class=\"line\">          visible: <span class=\"string\">'hover'</span>,</span><br><span class=\"line\">          placement: <span class=\"string\">'left'</span>,</span><br><span class=\"line\">          icon: ℬ <span class=\"comment\">// this is the header anchor \"unicode\" icon</span></span><br><span class=\"line\">        &#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Hexo-Basics\"><a href=\"#Hexo-Basics\" class=\"headerlink\" title=\"Hexo Basics\"></a>Hexo Basics</h2><hr>\n<p>Some hexo command:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new post <span class=\"string\">\"&lt;post name&gt;\"</span> <span class=\"comment\"># you can change post to another layout if you want</span></span><br><span class=\"line\">hexo clean &amp;&amp; hexo generate <span class=\"comment\"># generate the static file</span></span><br><span class=\"line\">hexo server <span class=\"comment\"># run hexo in local environment</span></span><br><span class=\"line\">hexo deploy <span class=\"comment\"># hexo will push the static files automatically into the specific branch(gh-pages) of your repo!</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Have-fun\"><a href=\"#Have-fun\" class=\"headerlink\" title=\"Have fun ^_^\"></a>Have fun ^_^</h1><hr>\n<!-- Place this tag in your head or just before your close body tag. -->\n<p><script async defer src=\"https://buttons.github.io/buttons.js\"></script><br><!-- Place this tag where you want the button to render. --></p>\n<p>Please <a class=\"github-button\" href=\"https://github.com/huweihuang/hexo-theme-huweihuang\" data-icon=\"octicon-star\" aria-label=\"Star huweihuang/hexo-theme-huweihuang on GitHub\" target=\"_blank\" rel=\"noopener\">Star</a> this Project if you like it! <a class=\"github-button\" href=\"https://github.com/huweihuang\" aria-label=\"Follow @huweihuang on GitHub\" target=\"_blank\" rel=\"noopener\">Follow</a> would also be appreciated!<br>Peace!</p>\n"},{"title":"[Hexo] HexoBug","catalog":true,"toc_nav_num":true,"date":"2019-07-16T05:08:47.000Z","subtitle":"Bugs encountered when using this hexo theme and their respective solutions","header-img":"Demo.png","top":0,"catagories":["hexo"],"_content":"\n> 本文记录了在适用Hexo Hux系列时遇到的一些bug和解决方案的链接\n\n\n## 公式渲染\n- 行间、行内公式无法渲染的解决方案  \n参考: https://nathaniel.blog/tutorials/make-hexo-support-math-again/\n\n\n## github 部署\n- 问题： username.github.io 404\n- 解决： \n    1. 检查repo命名，前缀需要与github用户名相同\n    2. 先hexo init后git init，否则会从根目录push。需要重新hexo init并转移文件\n\n## module\n- 找不到module, npm install module-name, 速度慢，加命令行代理proxychains4  \n参考: https://www.hi-linux.com/posts/48321.html\n","source":"_posts/hexobug.md","raw":"---\ntitle: \"[Hexo] HexoBug\"\ncatalog: true\ntoc_nav_num: true\ndate: 2019-07-16 13:08:47\nsubtitle: \"Bugs encountered when using this hexo theme and their respective solutions\"\nheader-img: \"Demo.png\"\ntop: 0\ntags:\n- hexo\ncatagories:\n- hexo\n---\n\n> 本文记录了在适用Hexo Hux系列时遇到的一些bug和解决方案的链接\n\n\n## 公式渲染\n- 行间、行内公式无法渲染的解决方案  \n参考: https://nathaniel.blog/tutorials/make-hexo-support-math-again/\n\n\n## github 部署\n- 问题： username.github.io 404\n- 解决： \n    1. 检查repo命名，前缀需要与github用户名相同\n    2. 先hexo init后git init，否则会从根目录push。需要重新hexo init并转移文件\n\n## module\n- 找不到module, npm install module-name, 速度慢，加命令行代理proxychains4  \n参考: https://www.hi-linux.com/posts/48321.html\n","slug":"hexobug","published":1,"updated":"2019-07-16T05:24:33.073Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyiirp5f0009o8heno55pgg3","content":"<blockquote>\n<p>本文记录了在适用Hexo Hux系列时遇到的一些bug和解决方案的链接</p>\n</blockquote>\n<h2 id=\"公式渲染\"><a href=\"#公式渲染\" class=\"headerlink\" title=\"公式渲染\"></a>公式渲染</h2><ul>\n<li>行间、行内公式无法渲染的解决方案<br>参考: <a href=\"https://nathaniel.blog/tutorials/make-hexo-support-math-again/\" target=\"_blank\" rel=\"noopener\">https://nathaniel.blog/tutorials/make-hexo-support-math-again/</a></li>\n</ul>\n<h2 id=\"github-部署\"><a href=\"#github-部署\" class=\"headerlink\" title=\"github 部署\"></a>github 部署</h2><ul>\n<li>问题： username.github.io 404</li>\n<li>解决： <ol>\n<li>检查repo命名，前缀需要与github用户名相同</li>\n<li>先hexo init后git init，否则会从根目录push。需要重新hexo init并转移文件</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"module\"><a href=\"#module\" class=\"headerlink\" title=\"module\"></a>module</h2><ul>\n<li>找不到module, npm install module-name, 速度慢，加命令行代理proxychains4<br>参考: <a href=\"https://www.hi-linux.com/posts/48321.html\" target=\"_blank\" rel=\"noopener\">https://www.hi-linux.com/posts/48321.html</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文记录了在适用Hexo Hux系列时遇到的一些bug和解决方案的链接</p>\n</blockquote>\n<h2 id=\"公式渲染\"><a href=\"#公式渲染\" class=\"headerlink\" title=\"公式渲染\"></a>公式渲染</h2><ul>\n<li>行间、行内公式无法渲染的解决方案<br>参考: <a href=\"https://nathaniel.blog/tutorials/make-hexo-support-math-again/\" target=\"_blank\" rel=\"noopener\">https://nathaniel.blog/tutorials/make-hexo-support-math-again/</a></li>\n</ul>\n<h2 id=\"github-部署\"><a href=\"#github-部署\" class=\"headerlink\" title=\"github 部署\"></a>github 部署</h2><ul>\n<li>问题： username.github.io 404</li>\n<li>解决： <ol>\n<li>检查repo命名，前缀需要与github用户名相同</li>\n<li>先hexo init后git init，否则会从根目录push。需要重新hexo init并转移文件</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"module\"><a href=\"#module\" class=\"headerlink\" title=\"module\"></a>module</h2><ul>\n<li>找不到module, npm install module-name, 速度慢，加命令行代理proxychains4<br>参考: <a href=\"https://www.hi-linux.com/posts/48321.html\" target=\"_blank\" rel=\"noopener\">https://www.hi-linux.com/posts/48321.html</a></li>\n</ul>\n"},{"title":"[Awk] Awk Scripts","catalog":true,"toc_nav_num":true,"date":"2019-07-15T10:40:06.000Z","subtitle":"Aggregation of awk techniques and examples","header-img":"Demo.png","top":0,"catagories":["scripts"],"_content":"> 本文收录了工作中用到的经典的awk脚本, 并通过这些脚本解释awk的一些语法和技巧\n\n# speech processing\n\n## common\n\n###  sort\\_to\\_field.awk\n\n- 目标\n\n#### AWK 脚本\n\n```awk\nFNR==NR{\n    record[$f] = $0\n}\nFNR != NR {\n    if ($f in record)\n        print record[$f]\n}\n```\n\n\n---\n\n## VAD\n\n### compare\\_mlf.awk \n\n- 目标: 对比两个mlf标注文件中，标注一致和不一致的时间段 (compare\\_mlf.awk 1.mlf 2.mlf)\n- 介绍: mlf文件是描述音频vad的常用格式, 是一行[uttid]后接着若干行[start end spc/sil]格式的对某一段时间是语音帧/静音帧的判定\n\n---\n\n#### AWK 知识\n\n1. PROCINFO 控制遍历列表的顺序，取值包括:\n    - \"@unsorted\" (默认)\n    - \"@ind\\_num\\_asc\", \"ind\\_num\\_desc\" (按索引大小排序)\n    - \"@val\\_type\\_asc\" (按值类型排序，数字在字符串前)\n    - \"@val\\_str\\_asc\"\n    - etc.\n2. ARGIND 记录当前文件在ARGV中的索引，从1开始\n3. asort(src, dest, method) 第三个参数从PROCINFO中取值\n\n---\n\n#### AWK 脚本\n\n```awk\n#! /bin/awk -f\nfunction get_frame_type(_frame2type, target)\n{\n    PROCINFO[\"sorted_in\"]=\"@ind_num_asc\";\n    for (_frame in _frame2type)\n        if (_frame+0 >= target+0)\n            return _frame2type[_frame]==0 ? \"sil\":\"spc\";\n    return _frame2type[_frame]==0 ? \"sil\":\"spc\";\n}\nNF==1{\n    uttid=$1;\n}\nNF>1{\n    frame2type[ARGIND][uttid][$2+0] = ($3==\"sil\" ? 0:1);\n    frames[uttid][$2] = $2; \n    uttids[uttid]=uttid;\n    idx2file[ARGIND]=FILENAME;\n}\nEND {\n    printf \"%-8s%-8s%-9s\", \"start\", \"end\", \"durat\";\n    for (idx_file in idx2file)\n        printf \"%-8s\", substr(idx2file[idx_file], 1,7);\n    printf \"%-8s\\n\\n\", \"judge\";\n\n    PROCINFO[\"sorted_in\"]=\"@ind_str_asc\";\n    for (uttid in uttids)\n    {   \n        print uttid;\n        start=0;\n        PROCINFO[\"sorted_in\"]=\"@ind_num_asc\";\n        for(frame in frames[uttid])\n        {\n            if (frame+0 <= start+0)  continue;\n            printf \"%-8s%-8s%-9s\", start, frame, frame - start;\n            judge = \"same\"; _type=-1;\n            for (idx_file in idx2file)\n            {\n                _type_new = get_frame_type(frame2type[idx_file][uttid], frame);\n                printf \"%-8s\", _type_new;\n                if (_type != -1 && _type != _type_new)\n                    judge = \"diff\";\n                _type = _type_new;\n            }\n            printf \"%-8s\\n\", judge;\n            start=frame;\n        }\n        printf \"\\n\";\n    }   \n}\n```\n\n---\n\n- mlf示例文件\n\n```text\n440c02010\n0       610     sil\n610     4680    spc\n4680    5730    sil\n\n440c02017\n0       610     sil\n610     4680    spc\n4680    5730    sil\n```\n\n```text\n440c02010\n0       620     sil\n620     1600    spc\n1600    1810    sil\n1810    4720    spc\n4720    5730    sil\n\n440c02017\n0       620     sil\n620     1540    spc\n1540    1560    sil\n1560    1570    spc\n1570    1820    sil\n1820    4590    spc\n4590    4600    sil\n4600    4610    spc\n4610    5730    sil\n```\n\n---\n\n- 示例输出 (compare\\_mlf.awk 1.mlf 2.mlf)\n\n```text\nstart   end     durat    gold.ml pred.lo judge   \n\n440c02010\n0       610     610      sil     sil     same    \n610     620     10       spc     sil     diff    \n620     1600    980      spc     spc     same    \n1600    1810    210      spc     sil     diff    \n1810    4680    2870     spc     spc     same    \n4680    4720    40       sil     spc     diff    \n4720    5730    1010     sil     sil     same    \n\n440c02017\n0       610     610      sil     sil     same    \n610     620     10       spc     sil     diff    \n620     1540    920      spc     spc     same    \n1540    1560    20       spc     sil     diff    \n1560    1570    10       spc     spc     same    \n1570    1820    250      spc     sil     diff    \n1820    4590    2770     spc     spc     same    \n4590    4600    10       spc     sil     diff    \n4600    4610    10       spc     spc     same    \n4610    4680    70       spc     sil     diff    \n4680    5730    1050     sil     sil     same \n\n```\n","source":"_posts/scripts.md","raw":"---\ntitle: \"[Awk] Awk Scripts\"\ncatalog: true\ntoc_nav_num: true\ndate: 2019-07-15 18:40:06\nsubtitle: \"Aggregation of awk techniques and examples\"\nheader-img: \"Demo.png\"\ntop: 0\ntags:\n- scripts\n- awk\ncatagories:\n- scripts\n---\n> 本文收录了工作中用到的经典的awk脚本, 并通过这些脚本解释awk的一些语法和技巧\n\n# speech processing\n\n## common\n\n###  sort\\_to\\_field.awk\n\n- 目标\n\n#### AWK 脚本\n\n```awk\nFNR==NR{\n    record[$f] = $0\n}\nFNR != NR {\n    if ($f in record)\n        print record[$f]\n}\n```\n\n\n---\n\n## VAD\n\n### compare\\_mlf.awk \n\n- 目标: 对比两个mlf标注文件中，标注一致和不一致的时间段 (compare\\_mlf.awk 1.mlf 2.mlf)\n- 介绍: mlf文件是描述音频vad的常用格式, 是一行[uttid]后接着若干行[start end spc/sil]格式的对某一段时间是语音帧/静音帧的判定\n\n---\n\n#### AWK 知识\n\n1. PROCINFO 控制遍历列表的顺序，取值包括:\n    - \"@unsorted\" (默认)\n    - \"@ind\\_num\\_asc\", \"ind\\_num\\_desc\" (按索引大小排序)\n    - \"@val\\_type\\_asc\" (按值类型排序，数字在字符串前)\n    - \"@val\\_str\\_asc\"\n    - etc.\n2. ARGIND 记录当前文件在ARGV中的索引，从1开始\n3. asort(src, dest, method) 第三个参数从PROCINFO中取值\n\n---\n\n#### AWK 脚本\n\n```awk\n#! /bin/awk -f\nfunction get_frame_type(_frame2type, target)\n{\n    PROCINFO[\"sorted_in\"]=\"@ind_num_asc\";\n    for (_frame in _frame2type)\n        if (_frame+0 >= target+0)\n            return _frame2type[_frame]==0 ? \"sil\":\"spc\";\n    return _frame2type[_frame]==0 ? \"sil\":\"spc\";\n}\nNF==1{\n    uttid=$1;\n}\nNF>1{\n    frame2type[ARGIND][uttid][$2+0] = ($3==\"sil\" ? 0:1);\n    frames[uttid][$2] = $2; \n    uttids[uttid]=uttid;\n    idx2file[ARGIND]=FILENAME;\n}\nEND {\n    printf \"%-8s%-8s%-9s\", \"start\", \"end\", \"durat\";\n    for (idx_file in idx2file)\n        printf \"%-8s\", substr(idx2file[idx_file], 1,7);\n    printf \"%-8s\\n\\n\", \"judge\";\n\n    PROCINFO[\"sorted_in\"]=\"@ind_str_asc\";\n    for (uttid in uttids)\n    {   \n        print uttid;\n        start=0;\n        PROCINFO[\"sorted_in\"]=\"@ind_num_asc\";\n        for(frame in frames[uttid])\n        {\n            if (frame+0 <= start+0)  continue;\n            printf \"%-8s%-8s%-9s\", start, frame, frame - start;\n            judge = \"same\"; _type=-1;\n            for (idx_file in idx2file)\n            {\n                _type_new = get_frame_type(frame2type[idx_file][uttid], frame);\n                printf \"%-8s\", _type_new;\n                if (_type != -1 && _type != _type_new)\n                    judge = \"diff\";\n                _type = _type_new;\n            }\n            printf \"%-8s\\n\", judge;\n            start=frame;\n        }\n        printf \"\\n\";\n    }   \n}\n```\n\n---\n\n- mlf示例文件\n\n```text\n440c02010\n0       610     sil\n610     4680    spc\n4680    5730    sil\n\n440c02017\n0       610     sil\n610     4680    spc\n4680    5730    sil\n```\n\n```text\n440c02010\n0       620     sil\n620     1600    spc\n1600    1810    sil\n1810    4720    spc\n4720    5730    sil\n\n440c02017\n0       620     sil\n620     1540    spc\n1540    1560    sil\n1560    1570    spc\n1570    1820    sil\n1820    4590    spc\n4590    4600    sil\n4600    4610    spc\n4610    5730    sil\n```\n\n---\n\n- 示例输出 (compare\\_mlf.awk 1.mlf 2.mlf)\n\n```text\nstart   end     durat    gold.ml pred.lo judge   \n\n440c02010\n0       610     610      sil     sil     same    \n610     620     10       spc     sil     diff    \n620     1600    980      spc     spc     same    \n1600    1810    210      spc     sil     diff    \n1810    4680    2870     spc     spc     same    \n4680    4720    40       sil     spc     diff    \n4720    5730    1010     sil     sil     same    \n\n440c02017\n0       610     610      sil     sil     same    \n610     620     10       spc     sil     diff    \n620     1540    920      spc     spc     same    \n1540    1560    20       spc     sil     diff    \n1560    1570    10       spc     spc     same    \n1570    1820    250      spc     sil     diff    \n1820    4590    2770     spc     spc     same    \n4590    4600    10       spc     sil     diff    \n4600    4610    10       spc     spc     same    \n4610    4680    70       spc     sil     diff    \n4680    5730    1050     sil     sil     same \n\n```\n","slug":"scripts","published":1,"updated":"2019-07-22T01:19:52.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyiirp5g000bo8helbtchslr","content":"<blockquote>\n<p>本文收录了工作中用到的经典的awk脚本, 并通过这些脚本解释awk的一些语法和技巧</p>\n</blockquote>\n<h1 id=\"speech-processing\"><a href=\"#speech-processing\" class=\"headerlink\" title=\"speech processing\"></a>speech processing</h1><h2 id=\"common\"><a href=\"#common\" class=\"headerlink\" title=\"common\"></a>common</h2><h3 id=\"sort-to-field-awk\"><a href=\"#sort-to-field-awk\" class=\"headerlink\" title=\"sort_to_field.awk\"></a>sort_to_field.awk</h3><ul>\n<li>目标</li>\n</ul>\n<h4 id=\"AWK-脚本\"><a href=\"#AWK-脚本\" class=\"headerlink\" title=\"AWK 脚本\"></a>AWK 脚本</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FNR==NR&#123;</span><br><span class=\"line\">    record[<span class=\"variable\">$f</span>] = <span class=\"variable\">$0</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">FNR != NR &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable\">$f</span> <span class=\"keyword\">in</span> record)</span><br><span class=\"line\">        print record[<span class=\"variable\">$f</span>]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<hr>\n<h2 id=\"VAD\"><a href=\"#VAD\" class=\"headerlink\" title=\"VAD\"></a>VAD</h2><h3 id=\"compare-mlf-awk\"><a href=\"#compare-mlf-awk\" class=\"headerlink\" title=\"compare_mlf.awk\"></a>compare_mlf.awk</h3><ul>\n<li>目标: 对比两个mlf标注文件中，标注一致和不一致的时间段 (compare_mlf.awk 1.mlf 2.mlf)</li>\n<li>介绍: mlf文件是描述音频vad的常用格式, 是一行[uttid]后接着若干行[start end spc/sil]格式的对某一段时间是语音帧/静音帧的判定</li>\n</ul>\n<hr>\n<h4 id=\"AWK-知识\"><a href=\"#AWK-知识\" class=\"headerlink\" title=\"AWK 知识\"></a>AWK 知识</h4><ol>\n<li>PROCINFO 控制遍历列表的顺序，取值包括:<ul>\n<li>“@unsorted” (默认)</li>\n<li>“@ind_num_asc”, “ind_num_desc” (按索引大小排序)</li>\n<li>“@val_type_asc” (按值类型排序，数字在字符串前)</li>\n<li>“@val_str_asc”</li>\n<li>etc.</li>\n</ul>\n</li>\n<li>ARGIND 记录当前文件在ARGV中的索引，从1开始</li>\n<li>asort(src, dest, method) 第三个参数从PROCINFO中取值</li>\n</ol>\n<hr>\n<h4 id=\"AWK-脚本-1\"><a href=\"#AWK-脚本-1\" class=\"headerlink\" title=\"AWK 脚本\"></a>AWK 脚本</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#! /bin/awk -f</span></span><br><span class=\"line\"><span class=\"keyword\">function</span> get_frame_type(_frame2type, target)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    PROCINFO[<span class=\"string\">\"sorted_in\"</span>]=<span class=\"string\">\"@ind_num_asc\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (_frame <span class=\"keyword\">in</span> _frame2type)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (_frame+<span class=\"number\">0</span> &gt;= target+<span class=\"number\">0</span>)</span><br><span class=\"line\">            return _frame2type[_frame]==<span class=\"number\">0</span> ? <span class=\"string\">\"sil\"</span>:<span class=\"string\">\"spc\"</span>;</span><br><span class=\"line\">    return _frame2type[_frame]==<span class=\"number\">0</span> ? <span class=\"string\">\"sil\"</span>:<span class=\"string\">\"spc\"</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">NF==<span class=\"number\">1</span>&#123;</span><br><span class=\"line\">    uttid=<span class=\"variable\">$1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">NF&gt;<span class=\"number\">1</span>&#123;</span><br><span class=\"line\">    frame2type[ARGIND][uttid][<span class=\"variable\">$2</span>+<span class=\"number\">0</span>] = (<span class=\"variable\">$3</span>==<span class=\"string\">\"sil\"</span> ? <span class=\"number\">0</span>:<span class=\"number\">1</span>);</span><br><span class=\"line\">    frames[uttid][<span class=\"variable\">$2</span>] = <span class=\"variable\">$2</span>; </span><br><span class=\"line\">    uttids[uttid]=uttid;</span><br><span class=\"line\">    idx2file[ARGIND]=FILENAME;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">END</span> &#123;</span><br><span class=\"line\">    printf <span class=\"string\">\"%-8s%-8s%-9s\"</span>, <span class=\"string\">\"start\"</span>, <span class=\"string\">\"end\"</span>, <span class=\"string\">\"durat\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (idx_file <span class=\"keyword\">in</span> idx2file)</span><br><span class=\"line\">        printf <span class=\"string\">\"%-8s\"</span>, substr(idx2file[idx_file], <span class=\"number\">1</span>,<span class=\"number\">7</span>);</span><br><span class=\"line\">    printf <span class=\"string\">\"%-8s\\n\\n\"</span>, <span class=\"string\">\"judge\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    PROCINFO[<span class=\"string\">\"sorted_in\"</span>]=<span class=\"string\">\"@ind_str_asc\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (uttid <span class=\"keyword\">in</span> uttids)</span><br><span class=\"line\">    &#123;   </span><br><span class=\"line\">        print uttid;</span><br><span class=\"line\">        start=<span class=\"number\">0</span>;</span><br><span class=\"line\">        PROCINFO[<span class=\"string\">\"sorted_in\"</span>]=<span class=\"string\">\"@ind_num_asc\"</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(frame <span class=\"keyword\">in</span> frames[uttid])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (frame+<span class=\"number\">0</span> &lt;= start+<span class=\"number\">0</span>)  <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            printf <span class=\"string\">\"%-8s%-8s%-9s\"</span>, start, frame, frame - start;</span><br><span class=\"line\">            judge = <span class=\"string\">\"same\"</span>; _type=-<span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (idx_file <span class=\"keyword\">in</span> idx2file)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                _type_new = get_frame_type(frame2type[idx_file][uttid], frame);</span><br><span class=\"line\">                printf <span class=\"string\">\"%-8s\"</span>, _type_new;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (_type != -<span class=\"number\">1</span> &amp;&amp; _type != _type_new)</span><br><span class=\"line\">                    judge = <span class=\"string\">\"diff\"</span>;</span><br><span class=\"line\">                _type = _type_new;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            printf <span class=\"string\">\"%-8s\\n\"</span>, judge;</span><br><span class=\"line\">            start=frame;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        printf <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li>mlf示例文件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">440c02010</span><br><span class=\"line\">0       610     sil</span><br><span class=\"line\">610     4680    spc</span><br><span class=\"line\">4680    5730    sil</span><br><span class=\"line\"></span><br><span class=\"line\">440c02017</span><br><span class=\"line\">0       610     sil</span><br><span class=\"line\">610     4680    spc</span><br><span class=\"line\">4680    5730    sil</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">440c02010</span><br><span class=\"line\">0       620     sil</span><br><span class=\"line\">620     1600    spc</span><br><span class=\"line\">1600    1810    sil</span><br><span class=\"line\">1810    4720    spc</span><br><span class=\"line\">4720    5730    sil</span><br><span class=\"line\"></span><br><span class=\"line\">440c02017</span><br><span class=\"line\">0       620     sil</span><br><span class=\"line\">620     1540    spc</span><br><span class=\"line\">1540    1560    sil</span><br><span class=\"line\">1560    1570    spc</span><br><span class=\"line\">1570    1820    sil</span><br><span class=\"line\">1820    4590    spc</span><br><span class=\"line\">4590    4600    sil</span><br><span class=\"line\">4600    4610    spc</span><br><span class=\"line\">4610    5730    sil</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li>示例输出 (compare_mlf.awk 1.mlf 2.mlf)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">start   end     durat    gold.ml pred.lo judge   </span><br><span class=\"line\"></span><br><span class=\"line\">440c02010</span><br><span class=\"line\">0       610     610      sil     sil     same    </span><br><span class=\"line\">610     620     10       spc     sil     diff    </span><br><span class=\"line\">620     1600    980      spc     spc     same    </span><br><span class=\"line\">1600    1810    210      spc     sil     diff    </span><br><span class=\"line\">1810    4680    2870     spc     spc     same    </span><br><span class=\"line\">4680    4720    40       sil     spc     diff    </span><br><span class=\"line\">4720    5730    1010     sil     sil     same    </span><br><span class=\"line\"></span><br><span class=\"line\">440c02017</span><br><span class=\"line\">0       610     610      sil     sil     same    </span><br><span class=\"line\">610     620     10       spc     sil     diff    </span><br><span class=\"line\">620     1540    920      spc     spc     same    </span><br><span class=\"line\">1540    1560    20       spc     sil     diff    </span><br><span class=\"line\">1560    1570    10       spc     spc     same    </span><br><span class=\"line\">1570    1820    250      spc     sil     diff    </span><br><span class=\"line\">1820    4590    2770     spc     spc     same    </span><br><span class=\"line\">4590    4600    10       spc     sil     diff    </span><br><span class=\"line\">4600    4610    10       spc     spc     same    </span><br><span class=\"line\">4610    4680    70       spc     sil     diff    </span><br><span class=\"line\">4680    5730    1050     sil     sil     same</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文收录了工作中用到的经典的awk脚本, 并通过这些脚本解释awk的一些语法和技巧</p>\n</blockquote>\n<h1 id=\"speech-processing\"><a href=\"#speech-processing\" class=\"headerlink\" title=\"speech processing\"></a>speech processing</h1><h2 id=\"common\"><a href=\"#common\" class=\"headerlink\" title=\"common\"></a>common</h2><h3 id=\"sort-to-field-awk\"><a href=\"#sort-to-field-awk\" class=\"headerlink\" title=\"sort_to_field.awk\"></a>sort_to_field.awk</h3><ul>\n<li>目标</li>\n</ul>\n<h4 id=\"AWK-脚本\"><a href=\"#AWK-脚本\" class=\"headerlink\" title=\"AWK 脚本\"></a>AWK 脚本</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FNR==NR&#123;</span><br><span class=\"line\">    record[<span class=\"variable\">$f</span>] = <span class=\"variable\">$0</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">FNR != NR &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable\">$f</span> <span class=\"keyword\">in</span> record)</span><br><span class=\"line\">        print record[<span class=\"variable\">$f</span>]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<hr>\n<h2 id=\"VAD\"><a href=\"#VAD\" class=\"headerlink\" title=\"VAD\"></a>VAD</h2><h3 id=\"compare-mlf-awk\"><a href=\"#compare-mlf-awk\" class=\"headerlink\" title=\"compare_mlf.awk\"></a>compare_mlf.awk</h3><ul>\n<li>目标: 对比两个mlf标注文件中，标注一致和不一致的时间段 (compare_mlf.awk 1.mlf 2.mlf)</li>\n<li>介绍: mlf文件是描述音频vad的常用格式, 是一行[uttid]后接着若干行[start end spc/sil]格式的对某一段时间是语音帧/静音帧的判定</li>\n</ul>\n<hr>\n<h4 id=\"AWK-知识\"><a href=\"#AWK-知识\" class=\"headerlink\" title=\"AWK 知识\"></a>AWK 知识</h4><ol>\n<li>PROCINFO 控制遍历列表的顺序，取值包括:<ul>\n<li>“@unsorted” (默认)</li>\n<li>“@ind_num_asc”, “ind_num_desc” (按索引大小排序)</li>\n<li>“@val_type_asc” (按值类型排序，数字在字符串前)</li>\n<li>“@val_str_asc”</li>\n<li>etc.</li>\n</ul>\n</li>\n<li>ARGIND 记录当前文件在ARGV中的索引，从1开始</li>\n<li>asort(src, dest, method) 第三个参数从PROCINFO中取值</li>\n</ol>\n<hr>\n<h4 id=\"AWK-脚本-1\"><a href=\"#AWK-脚本-1\" class=\"headerlink\" title=\"AWK 脚本\"></a>AWK 脚本</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#! /bin/awk -f</span></span><br><span class=\"line\"><span class=\"keyword\">function</span> get_frame_type(_frame2type, target)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    PROCINFO[<span class=\"string\">\"sorted_in\"</span>]=<span class=\"string\">\"@ind_num_asc\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (_frame <span class=\"keyword\">in</span> _frame2type)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (_frame+<span class=\"number\">0</span> &gt;= target+<span class=\"number\">0</span>)</span><br><span class=\"line\">            return _frame2type[_frame]==<span class=\"number\">0</span> ? <span class=\"string\">\"sil\"</span>:<span class=\"string\">\"spc\"</span>;</span><br><span class=\"line\">    return _frame2type[_frame]==<span class=\"number\">0</span> ? <span class=\"string\">\"sil\"</span>:<span class=\"string\">\"spc\"</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">NF==<span class=\"number\">1</span>&#123;</span><br><span class=\"line\">    uttid=<span class=\"variable\">$1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">NF&gt;<span class=\"number\">1</span>&#123;</span><br><span class=\"line\">    frame2type[ARGIND][uttid][<span class=\"variable\">$2</span>+<span class=\"number\">0</span>] = (<span class=\"variable\">$3</span>==<span class=\"string\">\"sil\"</span> ? <span class=\"number\">0</span>:<span class=\"number\">1</span>);</span><br><span class=\"line\">    frames[uttid][<span class=\"variable\">$2</span>] = <span class=\"variable\">$2</span>; </span><br><span class=\"line\">    uttids[uttid]=uttid;</span><br><span class=\"line\">    idx2file[ARGIND]=FILENAME;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">END</span> &#123;</span><br><span class=\"line\">    printf <span class=\"string\">\"%-8s%-8s%-9s\"</span>, <span class=\"string\">\"start\"</span>, <span class=\"string\">\"end\"</span>, <span class=\"string\">\"durat\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (idx_file <span class=\"keyword\">in</span> idx2file)</span><br><span class=\"line\">        printf <span class=\"string\">\"%-8s\"</span>, substr(idx2file[idx_file], <span class=\"number\">1</span>,<span class=\"number\">7</span>);</span><br><span class=\"line\">    printf <span class=\"string\">\"%-8s\\n\\n\"</span>, <span class=\"string\">\"judge\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    PROCINFO[<span class=\"string\">\"sorted_in\"</span>]=<span class=\"string\">\"@ind_str_asc\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (uttid <span class=\"keyword\">in</span> uttids)</span><br><span class=\"line\">    &#123;   </span><br><span class=\"line\">        print uttid;</span><br><span class=\"line\">        start=<span class=\"number\">0</span>;</span><br><span class=\"line\">        PROCINFO[<span class=\"string\">\"sorted_in\"</span>]=<span class=\"string\">\"@ind_num_asc\"</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(frame <span class=\"keyword\">in</span> frames[uttid])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (frame+<span class=\"number\">0</span> &lt;= start+<span class=\"number\">0</span>)  <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            printf <span class=\"string\">\"%-8s%-8s%-9s\"</span>, start, frame, frame - start;</span><br><span class=\"line\">            judge = <span class=\"string\">\"same\"</span>; _type=-<span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (idx_file <span class=\"keyword\">in</span> idx2file)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                _type_new = get_frame_type(frame2type[idx_file][uttid], frame);</span><br><span class=\"line\">                printf <span class=\"string\">\"%-8s\"</span>, _type_new;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (_type != -<span class=\"number\">1</span> &amp;&amp; _type != _type_new)</span><br><span class=\"line\">                    judge = <span class=\"string\">\"diff\"</span>;</span><br><span class=\"line\">                _type = _type_new;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            printf <span class=\"string\">\"%-8s\\n\"</span>, judge;</span><br><span class=\"line\">            start=frame;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        printf <span class=\"string\">\"\\n\"</span>;</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li>mlf示例文件</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">440c02010</span><br><span class=\"line\">0       610     sil</span><br><span class=\"line\">610     4680    spc</span><br><span class=\"line\">4680    5730    sil</span><br><span class=\"line\"></span><br><span class=\"line\">440c02017</span><br><span class=\"line\">0       610     sil</span><br><span class=\"line\">610     4680    spc</span><br><span class=\"line\">4680    5730    sil</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">440c02010</span><br><span class=\"line\">0       620     sil</span><br><span class=\"line\">620     1600    spc</span><br><span class=\"line\">1600    1810    sil</span><br><span class=\"line\">1810    4720    spc</span><br><span class=\"line\">4720    5730    sil</span><br><span class=\"line\"></span><br><span class=\"line\">440c02017</span><br><span class=\"line\">0       620     sil</span><br><span class=\"line\">620     1540    spc</span><br><span class=\"line\">1540    1560    sil</span><br><span class=\"line\">1560    1570    spc</span><br><span class=\"line\">1570    1820    sil</span><br><span class=\"line\">1820    4590    spc</span><br><span class=\"line\">4590    4600    sil</span><br><span class=\"line\">4600    4610    spc</span><br><span class=\"line\">4610    5730    sil</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li>示例输出 (compare_mlf.awk 1.mlf 2.mlf)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">start   end     durat    gold.ml pred.lo judge   </span><br><span class=\"line\"></span><br><span class=\"line\">440c02010</span><br><span class=\"line\">0       610     610      sil     sil     same    </span><br><span class=\"line\">610     620     10       spc     sil     diff    </span><br><span class=\"line\">620     1600    980      spc     spc     same    </span><br><span class=\"line\">1600    1810    210      spc     sil     diff    </span><br><span class=\"line\">1810    4680    2870     spc     spc     same    </span><br><span class=\"line\">4680    4720    40       sil     spc     diff    </span><br><span class=\"line\">4720    5730    1010     sil     sil     same    </span><br><span class=\"line\"></span><br><span class=\"line\">440c02017</span><br><span class=\"line\">0       610     610      sil     sil     same    </span><br><span class=\"line\">610     620     10       spc     sil     diff    </span><br><span class=\"line\">620     1540    920      spc     spc     same    </span><br><span class=\"line\">1540    1560    20       spc     sil     diff    </span><br><span class=\"line\">1560    1570    10       spc     spc     same    </span><br><span class=\"line\">1570    1820    250      spc     sil     diff    </span><br><span class=\"line\">1820    4590    2770     spc     spc     same    </span><br><span class=\"line\">4590    4600    10       spc     sil     diff    </span><br><span class=\"line\">4600    4610    10       spc     spc     same    </span><br><span class=\"line\">4610    4680    70       spc     sil     diff    </span><br><span class=\"line\">4680    5730    1050     sil     sil     same</span><br></pre></td></tr></table></figure>\n"}],"PostAsset":[{"_id":"source/_posts/EM/Demo.png","slug":"Demo.png","post":"cjyiirp540001o8hemqrbxyjh","modified":0,"renderable":0},{"_id":"source/_posts/GMM/Demo.png","slug":"Demo.png","post":"cjyiirp590003o8he7mjy77iv","modified":0,"renderable":0},{"_id":"source/_posts/HMM/Demo.png","slug":"Demo.png","post":"cjyiirp5c0006o8he7n29ep5m","modified":0,"renderable":0},{"_id":"source/_posts/hexo-theme-huweihuang/Demo.png","slug":"Demo.png","post":"cjyiirp5e0008o8hem4e599my","modified":0,"renderable":0},{"_id":"source/_posts/scripts/Demo.png","slug":"Demo.png","post":"cjyiirp5g000bo8helbtchslr","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"cjyiirp540001o8hemqrbxyjh","tag_id":"cjyiirp5b0005o8he06bbit83","_id":"cjyiirp5j000eo8hep8dnx5hy"},{"post_id":"cjyiirp540001o8hemqrbxyjh","tag_id":"cjyiirp5g000ao8hesi216ffv","_id":"cjyiirp5k000fo8he44bzu0co"},{"post_id":"cjyiirp540001o8hemqrbxyjh","tag_id":"cjyiirp5i000co8hejmlsaie3","_id":"cjyiirp5l000ho8het4w9onq3"},{"post_id":"cjyiirp590003o8he7mjy77iv","tag_id":"cjyiirp5j000do8helamtogio","_id":"cjyiirp5m000ko8hetcpmok1d"},{"post_id":"cjyiirp590003o8he7mjy77iv","tag_id":"cjyiirp5g000ao8hesi216ffv","_id":"cjyiirp5m000lo8hej2ygsqfd"},{"post_id":"cjyiirp590003o8he7mjy77iv","tag_id":"cjyiirp5i000co8hejmlsaie3","_id":"cjyiirp5m000no8hedrx23uhr"},{"post_id":"cjyiirp5c0006o8he7n29ep5m","tag_id":"cjyiirp5j000do8helamtogio","_id":"cjyiirp5n000qo8heizrzt57z"},{"post_id":"cjyiirp5c0006o8he7n29ep5m","tag_id":"cjyiirp5g000ao8hesi216ffv","_id":"cjyiirp5n000ro8heyiz0omic"},{"post_id":"cjyiirp5c0006o8he7n29ep5m","tag_id":"cjyiirp5i000co8hejmlsaie3","_id":"cjyiirp5n000to8he1gubmby3"},{"post_id":"cjyiirp5e0008o8hem4e599my","tag_id":"cjyiirp5n000po8he73c9b2ai","_id":"cjyiirp5n000uo8heamvrd521"},{"post_id":"cjyiirp5f0009o8heno55pgg3","tag_id":"cjyiirp5n000so8hef9ua1534","_id":"cjyiirp5o000wo8he46jznqmp"},{"post_id":"cjyiirp5g000bo8helbtchslr","tag_id":"cjyiirp5n000vo8heearc62eq","_id":"cjyiirp5o000yo8hegqf9h1mf"},{"post_id":"cjyiirp5g000bo8helbtchslr","tag_id":"cjyiirp5o000xo8heyf1e57vi","_id":"cjyiirp5o000zo8he30bca0hk"}],"Tag":[{"name":"algorithm","_id":"cjyiirp5b0005o8he06bbit83"},{"name":"optimization","_id":"cjyiirp5g000ao8hesi216ffv"},{"name":"EM","_id":"cjyiirp5i000co8hejmlsaie3"},{"name":"model","_id":"cjyiirp5j000do8helamtogio"},{"name":"Hexo","_id":"cjyiirp5n000po8he73c9b2ai"},{"name":"hexo","_id":"cjyiirp5n000so8hef9ua1534"},{"name":"scripts","_id":"cjyiirp5n000vo8heearc62eq"},{"name":"awk","_id":"cjyiirp5o000xo8heyf1e57vi"}]}}